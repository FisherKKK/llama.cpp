# Day 13: é‡‡æ ·ç­–ç•¥ä¸ç”Ÿæˆæ§åˆ¶

## è¯¾ç¨‹ç›®æ ‡

æŒæ¡ LLM æ–‡æœ¬ç”Ÿæˆçš„æ ¸å¿ƒæŠ€æœ¯ï¼š
- é‡‡æ ·ç®—æ³•åŸç†ä¸å®ç°
- Temperatureã€Top-Kã€Top-P è¯¦è§£
- Mirostat è‡ªé€‚åº”é‡‡æ ·
- é‡å¤æƒ©ç½šæœºåˆ¶
- å®æˆ˜ï¼šå®šåˆ¶é‡‡æ ·ç­–ç•¥

## 1. é‡‡æ ·é—®é¢˜æ¦‚è¿°

### 1.1 ä» Logits åˆ° Token

```
æ¨¡å‹è¾“å‡º logits: [n_vocab] ä¸ªåŸå§‹å¾—åˆ†
    â†“
å¦‚ä½•é€‰æ‹©ä¸‹ä¸€ä¸ª tokenï¼Ÿ

ç­–ç•¥1: Greedyï¼ˆè´ªå¿ƒï¼‰
   â†’ æ€»æ˜¯é€‰æœ€é«˜åˆ†çš„
   â†’ è¾“å‡ºç¡®å®šä½†å•è°ƒ

ç­–ç•¥2: éšæœºé‡‡æ ·
   â†’ æŒ‰æ¦‚ç‡éšæœºé€‰æ‹©
   â†’ è¾“å‡ºå¤šæ ·ä½†å¯èƒ½æ··ä¹±

ç­–ç•¥3: æ™ºèƒ½é‡‡æ · â­
   â†’ å¹³è¡¡è´¨é‡ä¸å¤šæ ·æ€§
   â†’ æœ¬è¯¾ç¨‹é‡ç‚¹
```

## 2. æ ¸å¿ƒé‡‡æ ·ç®—æ³•

### 2.1 Temperature Scalingï¼ˆæ¸©åº¦ç¼©æ”¾ï¼‰

**åŸç†**ï¼šè°ƒæ•´æ¦‚ç‡åˆ†å¸ƒçš„"å°–é”åº¦"

```python
# ä¼ªä»£ç 
logits_scaled = logits / temperature

if temperature < 1.0:
    # æ›´ç¡®å®šæ€§ï¼ˆæ¦‚ç‡é›†ä¸­ï¼‰
    # é«˜åˆ† token æ¦‚ç‡è¿›ä¸€æ­¥æå‡
    probs = softmax([10, 8, 2]) @ T=0.5
        = [0.9, 0.09, 0.01]  # æ›´é›†ä¸­

elif temperature > 1.0:
    # æ›´éšæœºï¼ˆæ¦‚ç‡å¹³ç¼“ï¼‰
    # ä½åˆ† token ä¹Ÿæœ‰æœºä¼š
    probs = softmax([10, 8, 2]) @ T=2.0
        = [0.6, 0.35, 0.05]  # æ›´å¹³å‡

elif temperature == 1.0:
    # åŸå§‹åˆ†å¸ƒ
    probs = softmax([10, 8, 2])
        = [0.73, 0.24, 0.03]
```

**ä»£ç å®ç°**ï¼ˆä½ç½®ï¼š`src/llama-sampling.cpp:478`ï¼‰ï¼š

```cpp
void llama_sampler_sample_temp(
    struct llama_token_data_array * cur_p,
    float temp) {

    if (temp <= 0.0f) {
        // Temperature = 0 ç­‰åŒäº greedy
        cur_p->selected = cur_p->data[0].id;
        return;
    }

    // å¯¹æ‰€æœ‰ logits ç¼©æ”¾
    for (size_t i = 0; i < cur_p->size; ++i) {
        cur_p->data[i].logit /= temp;
    }
}
```

**æ•ˆæœå¯¹æ¯”**ï¼š
- `temp=0.0`: å®Œå…¨ç¡®å®šï¼Œé€‚åˆä»£ç ç”Ÿæˆã€æ•°å­¦æ¨ç†
- `temp=0.7`: ç•¥æœ‰åˆ›æ„ï¼Œé€‚åˆä¸€èˆ¬å¯¹è¯
- `temp=1.0`: åŸå§‹åˆ†å¸ƒ
- `temp=1.5`: å¾ˆæœ‰åˆ›æ„ï¼Œé€‚åˆåˆ›æ„å†™ä½œ
- `temp=2.0+`: éå¸¸éšæœºï¼Œå¯èƒ½äº§ç”Ÿæ— æ„ä¹‰è¾“å‡º

### 2.2 Top-K Sampling

**åŸç†**ï¼šåªä¿ç•™æ¦‚ç‡æœ€é«˜çš„ K ä¸ª token

```python
# ä¼ªä»£ç 
def top_k_sampling(logits, k=40):
    # 1. æ’åº
    sorted_indices = argsort(logits, descending=True)

    # 2. åªä¿ç•™å‰ k ä¸ª
    keep_indices = sorted_indices[:k]

    # 3. å…¶ä»–è®¾ä¸º -infï¼ˆæ¦‚ç‡ä¸º0ï¼‰
    logits[~keep_indices] = -float('inf')

    # 4. é‡æ–°å½’ä¸€åŒ–å¹¶é‡‡æ ·
    probs = softmax(logits)
    token = sample(probs)
    return token
```

**ä»£ç å®ç°**ï¼ˆä½ç½®ï¼š`src/llama-sampling.cpp:548`ï¼‰ï¼š

```cpp
void llama_sampler_sample_top_k(
    struct llama_token_data_array * cur_p,
    int32_t k) {

    if (k <= 0 || k >= (int32_t) cur_p->size) {
        return;  // ä¸è¿‡æ»¤
    }

    // 1. éƒ¨åˆ†æ’åºï¼Œæ‰¾åˆ°ç¬¬ k å¤§çš„å…ƒç´ 
    std::nth_element(
        cur_p->data,
        cur_p->data + k,
        cur_p->data + cur_p->size,
        [](const llama_token_data & a, const llama_token_data & b) {
            return a.logit > b.logit;
        });

    // 2. æˆªæ–­åˆ°å‰ k ä¸ª
    cur_p->size = k;
}
```

**é€‚ç”¨åœºæ™¯**ï¼š
- `k=1`: ç­‰åŒäº greedy
- `k=10`: éå¸¸ä¿å®ˆ
- `k=40`: å¸¸ç”¨é»˜è®¤å€¼
- `k=100+`: å‡ ä¹ä¸è¿‡æ»¤

### 2.3 Top-P (Nucleus) Sampling â­

**åŸç†**ï¼šåŠ¨æ€é€‰æ‹©ç´¯è®¡æ¦‚ç‡è¾¾åˆ° P çš„æœ€å° token é›†åˆ

```python
# ä¼ªä»£ç 
def top_p_sampling(logits, p=0.9):
    # 1. è®¡ç®—æ¦‚ç‡å¹¶æ’åº
    probs = softmax(logits)
    sorted_probs, sorted_indices = sort(probs, descending=True)

    # 2. è®¡ç®—ç´¯è®¡æ¦‚ç‡
    cumsum_probs = cumsum(sorted_probs)

    # 3. æ‰¾åˆ°ç´¯è®¡æ¦‚ç‡åˆšè¶…è¿‡ p çš„ä½ç½®
    cutoff_index = find_first(cumsum_probs > p)

    # 4. ä¿ç•™å‰ cutoff_index ä¸ª token
    keep_indices = sorted_indices[:cutoff_index]
    probs[~keep_indices] = 0

    # 5. é‡æ–°å½’ä¸€åŒ–å¹¶é‡‡æ ·
    probs = probs / sum(probs)
    token = sample(probs)
    return token
```

**ç¤ºä¾‹**ï¼š
```
åŸå§‹ logits: [10.0, 9.8, 7.0, 6.5, 3.0, 2.5, ...]
    â†“ softmax
æ¦‚ç‡:        [0.53, 0.25, 0.08, 0.06, 0.02, 0.01, ...]
    â†“ ç´¯è®¡
ç´¯è®¡æ¦‚ç‡:    [0.53, 0.78, 0.86, 0.92, 0.94, 0.95, ...]
             ^     ^     ^     ^
             |     |     |     +-- è¶…è¿‡ p=0.9ï¼Œæˆªæ–­è¿™é‡Œ

ä¿ç•™å‰ 4 ä¸ª token: [10.0, 9.8, 7.0, 6.5]
å¿½ç•¥å…¶ä½™ token
```

**ä»£ç å®ç°**ï¼ˆä½ç½®ï¼š`src/llama-sampling.cpp:590`ï¼‰ï¼š

```cpp
void llama_sampler_sample_top_p(
    struct llama_token_data_array * cur_p,
    float p) {

    if (p >= 1.0f) {
        return;  // ä¸è¿‡æ»¤
    }

    // 1. å…ˆ softmax
    llama_sampler_softmax_impl(cur_p);

    // 2. æŒ‰æ¦‚ç‡é™åºæ’åº
    std::sort(cur_p->data, cur_p->data + cur_p->size,
        [](const llama_token_data & a, const llama_token_data & b) {
            return a.p > b.p;
        });

    // 3. è®¡ç®—ç´¯è®¡æ¦‚ç‡
    float cum_sum = 0.0f;
    size_t last_idx = 0;

    for (size_t i = 0; i < cur_p->size; ++i) {
        cum_sum += cur_p->data[i].p;
        last_idx = i;

        if (cum_sum >= p) {
            break;
        }
    }

    // 4. æˆªæ–­
    cur_p->size = last_idx + 1;
}
```

**Top-P vs Top-K**ï¼š
- Top-K: å›ºå®šæ•°é‡ï¼Œå¯èƒ½å¤ªä¿å®ˆæˆ–å¤ªå®½æ¾
- Top-P: è‡ªé€‚åº”ï¼Œå§‹ç»ˆä¿ç•™"è¶³å¤Ÿå¥½"çš„ token é›†åˆ

**æ¨èé…ç½®**ï¼š
- å¯¹è¯ï¼š`p=0.9, temp=0.7`
- åˆ›æ„å†™ä½œï¼š`p=0.95, temp=1.2`
- ä»£ç ç”Ÿæˆï¼š`p=0.5, temp=0.2`

### 2.4 Min-P Sampling

**åŸç†**ï¼šè¿‡æ»¤æ‰æ¦‚ç‡ä½äº `max_prob * min_p` çš„ token

```cpp
// ä½ç½®ï¼šsrc/llama-sampling.cpp:653
void llama_sampler_sample_min_p(
    struct llama_token_data_array * cur_p,
    float min_p) {

    if (min_p <= 0.0f || cur_p->size == 0) {
        return;
    }

    // å…ˆ softmax
    llama_sampler_softmax_impl(cur_p);

    // æ‰¾æœ€å¤§æ¦‚ç‡
    float max_prob = cur_p->data[0].p;  // å·²æ’åº

    // è®¡ç®—é˜ˆå€¼
    float threshold = min_p * max_prob;

    // è¿‡æ»¤
    size_t keep_count = 0;
    for (size_t i = 0; i < cur_p->size; ++i) {
        if (cur_p->data[i].p >= threshold) {
            cur_p->data[keep_count++] = cur_p->data[i];
        }
    }

    cur_p->size = keep_count;
}
```

**ç”¨é€”**ï¼šé…åˆ Top-P ä½¿ç”¨ï¼Œè¿›ä¸€æ­¥è¿‡æ»¤ä½è´¨é‡ tokenã€‚

### 2.5 Mirostat â­ é«˜çº§ç®—æ³•

**åŸç†**ï¼šè‡ªé€‚åº”è°ƒæ•´æ¸©åº¦ï¼Œæ§åˆ¶è¾“å‡ºçš„"æƒŠå–œåº¦"ï¼ˆperplexityï¼‰

Mirostat è¯•å›¾ç»´æŒç›®æ ‡ perplexityï¼ˆå›°æƒ‘åº¦ï¼‰ï¼ŒåŠ¨æ€è°ƒæ•´é‡‡æ ·å‚æ•°ã€‚

```cpp
// ä½ç½®ï¼šsrc/llama-sampling.cpp:747
struct llama_sampler_mirostat_v2 {
    float tau;        // ç›®æ ‡ perplexity (é€šå¸¸ 5.0)
    float eta;        // å­¦ä¹ ç‡ (é€šå¸¸ 0.1)
    float mu;         // å½“å‰çŠ¶æ€ï¼ˆåŠ¨æ€è°ƒæ•´ï¼‰
};

void llama_sampler_sample_mirostat_v2(
    struct llama_sampler_mirostat_v2 * mirostat,
    struct llama_token_data_array * cur_p) {

    // 1. Softmax
    llama_sampler_softmax_impl(cur_p);

    // 2. è®¡ç®—å½“å‰ entropy
    float entropy = 0.0f;
    for (size_t i = 0; i < cur_p->size; ++i) {
        float p = cur_p->data[i].p;
        if (p > 0) {
            entropy -= p * logf(p);
        }
    }

    // 3. è®¡ç®—è¯¯å·®
    float error = entropy - logf(mirostat->tau);

    // 4. æ›´æ–° muï¼ˆè½¯é˜ˆå€¼ï¼‰
    mirostat->mu -= mirostat->eta * error;

    // 5. æ ¹æ® mu è¿‡æ»¤ token
    // ä¿ç•™ log(prob) >= -mu çš„ token
    size_t keep_count = 0;
    for (size_t i = 0; i < cur_p->size; ++i) {
        if (-logf(cur_p->data[i].p) <= mirostat->mu) {
            cur_p->data[keep_count++] = cur_p->data[i];
        }
    }
    cur_p->size = keep_count;

    // 6. é‡æ–°å½’ä¸€åŒ–å¹¶é‡‡æ ·
    llama_sampler_softmax_impl(cur_p);
    // ... sample
}
```

**Mirostat ä¼˜åŠ¿**ï¼š
- è‡ªåŠ¨å¹³è¡¡è´¨é‡ä¸å¤šæ ·æ€§
- å‡å°‘é‡å¤å’Œå‘æ•£
- é€‚åˆé•¿æ–‡æœ¬ç”Ÿæˆ

**æ¨èå‚æ•°**ï¼š
- `tau=5.0`: ç›®æ ‡å›°æƒ‘åº¦
- `eta=0.1`: è°ƒæ•´é€Ÿåº¦

## 3. é‡å¤æƒ©ç½š

### 3.1 ç®€å•é‡å¤æƒ©ç½š

**åŸç†**ï¼šé™ä½å·²å‡ºç° token çš„æ¦‚ç‡

```cpp
// ä½ç½®ï¼šsrc/llama-sampling.cpp:398
void llama_sampler_sample_repetition_penalty(
    struct llama_token_data_array * cur_p,
    const llama_token * last_tokens,
    size_t last_tokens_size,
    float penalty) {  // é€šå¸¸ 1.1 - 1.5

    if (penalty == 1.0f) {
        return;  // æ— æƒ©ç½š
    }

    // æ„å»ºå·²å‡ºç° token çš„é›†åˆ
    std::unordered_set<llama_token> token_set(
        last_tokens, last_tokens + last_tokens_size);

    // åº”ç”¨æƒ©ç½š
    for (size_t i = 0; i < cur_p->size; ++i) {
        llama_token token = cur_p->data[i].id;

        if (token_set.count(token)) {
            if (cur_p->data[i].logit >= 0) {
                // æ­£ logit é™¤ä»¥ penalty
                cur_p->data[i].logit /= penalty;
            } else {
                // è´Ÿ logit ä¹˜ä»¥ penalty
                cur_p->data[i].logit *= penalty;
            }
        }
    }
}
```

**æ•ˆæœ**ï¼š
- `penalty=1.0`: æ— æƒ©ç½š
- `penalty=1.1`: è½»å¾®æƒ©ç½šï¼Œé€‚åˆå¯¹è¯
- `penalty=1.3`: ä¸­ç­‰æƒ©ç½šï¼Œå‡å°‘é‡å¤
- `penalty=1.5+`: å¼ºæƒ©ç½šï¼Œå¯èƒ½å½±å“è¿è´¯æ€§

### 3.2 é¢‘ç‡/å‡ºç°æƒ©ç½šï¼ˆOpenAI é£æ ¼ï¼‰

```cpp
void llama_sampler_sample_frequency_presence_penalty(
    struct llama_token_data_array * cur_p,
    const std::map<llama_token, int> & token_count,
    float alpha_frequency,   // é¢‘ç‡æƒ©ç½šç³»æ•°
    float alpha_presence) {  // å‡ºç°æƒ©ç½šç³»æ•°

    for (size_t i = 0; i < cur_p->size; ++i) {
        llama_token token = cur_p->data[i].id;

        auto it = token_count.find(token);
        if (it != token_count.end()) {
            int count = it->second;

            // æƒ©ç½š = é¢‘ç‡æƒ©ç½š * count + å‡ºç°æƒ©ç½š
            float penalty = alpha_frequency * count + alpha_presence;
            cur_p->data[i].logit -= penalty;
        }
    }
}
```

**å‚æ•°è¯´æ˜**ï¼š
- `alpha_frequency`: ä¸å‡ºç°æ¬¡æ•°æˆæ­£æ¯”ï¼ˆæŠ‘åˆ¶é«˜é¢‘è¯ï¼‰
- `alpha_presence`: å›ºå®šæƒ©ç½šï¼ˆæŠ‘åˆ¶å·²å‡ºç°çš„è¯ï¼‰

**æ¨èé…ç½®**ï¼š
- å¯¹è¯ï¼š`freq=0.5, presence=0.5`
- åˆ›ä½œï¼š`freq=0.3, presence=0.3`

## 4. é‡‡æ ·é“¾ï¼ˆSampler Chainï¼‰

llama.cpp ä½¿ç”¨"é‡‡æ ·é“¾"ç»„åˆå¤šä¸ªé‡‡æ ·å™¨ï¼š

```cpp
// ä½ç½®ï¼šsrc/llama-sampling.cpp:1234
struct llama_sampler * llama_sampler_chain_init(
    struct llama_sampler_chain_params params) {

    auto * chain = new llama_sampler_chain();

    // 1. é‡å¤æƒ©ç½šï¼ˆä½œç”¨äº logitsï¼‰
    llama_sampler_chain_add(chain,
        llama_sampler_init_repetition_penalty(params.penalty_repeat));

    // 2. é¢‘ç‡/å‡ºç°æƒ©ç½š
    llama_sampler_chain_add(chain,
        llama_sampler_init_frequencies(
            params.penalty_freq, params.penalty_present));

    // 3. Top-K
    llama_sampler_chain_add(chain,
        llama_sampler_init_top_k(params.top_k));

    // 4. Top-P
    llama_sampler_chain_add(chain,
        llama_sampler_init_top_p(params.top_p));

    // 5. Min-P
    llama_sampler_chain_add(chain,
        llama_sampler_init_min_p(params.min_p));

    // 6. Temperature
    llama_sampler_chain_add(chain,
        llama_sampler_init_temp(params.temp));

    // 7. Mirostatï¼ˆå¯é€‰ï¼‰
    if (params.mirostat == 2) {
        llama_sampler_chain_add(chain,
            llama_sampler_init_mirostat_v2(params.mirostat_tau, params.mirostat_eta));
    }

    return chain;
}
```

**æ‰§è¡Œé¡ºåº**ï¼š
```
logits
  â†“
é‡å¤æƒ©ç½š (ä¿®æ”¹ logits)
  â†“
é¢‘ç‡æƒ©ç½š (ä¿®æ”¹ logits)
  â†“
Top-K (è¿‡æ»¤)
  â†“
Top-P (è¿‡æ»¤)
  â†“
Min-P (è¿‡æ»¤)
  â†“
Temperature (ç¼©æ”¾)
  â†“
Softmax (å½’ä¸€åŒ–)
  â†“
Mirostat (åŠ¨æ€è¿‡æ»¤ï¼Œå¯é€‰)
  â†“
é‡‡æ · (multinomial/greedy)
  â†“
selected token
```

## 5. å®æˆ˜ï¼šå®šåˆ¶é‡‡æ ·ç­–ç•¥

### 5.1 ä»£ç ç”Ÿæˆé‡‡æ ·å™¨

```cpp
struct llama_sampler * create_code_sampler() {
    auto params = llama_sampler_chain_default_params();

    // ä»£ç éœ€è¦ç¡®å®šæ€§
    params.temp = 0.2;              // ä½æ¸©åº¦
    params.top_p = 0.5;             // ä¸¥æ ¼è¿‡æ»¤
    params.top_k = 20;              // å°‘é‡å€™é€‰
    params.penalty_repeat = 1.05;   // è½»å¾®é‡å¤æƒ©ç½š
    params.penalty_freq = 0.0;      // ä¸æƒ©ç½šå¸¸ç”¨å…³é”®å­—
    params.penalty_present = 0.0;

    return llama_sampler_chain_init(params);
}
```

### 5.2 åˆ›æ„å†™ä½œé‡‡æ ·å™¨

```cpp
struct llama_sampler * create_creative_sampler() {
    auto params = llama_sampler_chain_default_params();

    // åˆ›æ„éœ€è¦å¤šæ ·æ€§
    params.temp = 1.3;              // é«˜æ¸©åº¦
    params.top_p = 0.95;            // å®½æ¾è¿‡æ»¤
    params.top_k = 100;             // å¤§é‡å€™é€‰
    params.penalty_repeat = 1.2;    // ä¸­ç­‰é‡å¤æƒ©ç½š
    params.penalty_freq = 0.5;      // é¿å…é«˜é¢‘è¯
    params.penalty_present = 0.3;

    return llama_sampler_chain_init(params);
}
```

### 5.3 Mirostat é‡‡æ ·å™¨

```cpp
struct llama_sampler * create_mirostat_sampler() {
    auto params = llama_sampler_chain_default_params();

    // ä½¿ç”¨ Mirostat è‡ªé€‚åº”
    params.mirostat = 2;
    params.mirostat_tau = 5.0;      // ç›®æ ‡å›°æƒ‘åº¦
    params.mirostat_eta = 0.1;      // å­¦ä¹ ç‡
    params.temp = 1.0;              // Mirostat ä¼šè‡ªåŠ¨è°ƒæ•´

    // ç¦ç”¨å…¶ä»–é‡‡æ ·å™¨ï¼ˆMirostat å·²åŒ…å«ï¼‰
    params.top_k = 0;
    params.top_p = 1.0;

    return llama_sampler_chain_init(params);
}
```

## 6. é«˜çº§æŠ€å·§

### 6.1 åŠ¨æ€è°ƒæ•´é‡‡æ ·å‚æ•°

```cpp
// æ ¹æ®ç”Ÿæˆé•¿åº¦åŠ¨æ€è°ƒæ•´
float get_temperature_for_length(int current_len, int max_len) {
    // å¼€å§‹æ—¶ä¿å®ˆï¼ŒåæœŸæ›´è‡ªç”±
    float progress = (float)current_len / max_len;

    if (progress < 0.3) {
        return 0.7;  // å‰30%è¾ƒä¿å®ˆ
    } else if (progress < 0.7) {
        return 1.0;  // ä¸­é—´æ­£å¸¸
    } else {
        return 1.2;  // æœ€åæ›´è‡ªç”±
    }
}
```

### 6.2 åŸºäºå›°æƒ‘åº¦çš„æ—©åœ

```cpp
bool should_stop_generation(
    const std::vector<float> & recent_probs) {

    // è®¡ç®—æœ€è¿‘å‡ ä¸ª token çš„å¹³å‡æ¦‚ç‡
    float avg_prob = std::accumulate(
        recent_probs.begin(), recent_probs.end(), 0.0f)
        / recent_probs.size();

    // å¦‚æœè¿ç»­å¤šä¸ª token æ¦‚ç‡å¾ˆä½ï¼Œå¯èƒ½æ˜¯æ¨¡å‹"è¿·å¤±"äº†
    if (avg_prob < 0.01f) {
        return true;  // æ—©åœ
    }

    return false;
}
```

### 6.3 å¤šæ ·æ€§æ³¢æŸæœç´¢ï¼ˆDiverse Beam Searchï¼‰

```cpp
struct beam {
    std::vector<llama_token> tokens;
    float score;
};

std::vector<beam> diverse_beam_search(
    llama_context * ctx,
    int n_beams = 5,
    float diversity_penalty = 0.5) {

    std::vector<beam> beams(n_beams);

    // åˆå§‹åŒ–
    for (int i = 0; i < n_beams; i++) {
        beams[i].score = 0.0f;
    }

    for (int step = 0; step < max_len; step++) {
        // å¯¹æ¯ä¸ª beam ç”Ÿæˆå€™é€‰
        for (int i = 0; i < n_beams; i++) {
            auto logits = llama_get_logits(ctx);

            // æƒ©ç½šå…¶ä»– beam å·²é€‰æ‹©çš„ token
            for (int j = 0; j < i; j++) {
                llama_token prev_token = beams[j].tokens.back();
                logits[prev_token] -= diversity_penalty;
            }

            // é‡‡æ ·
            llama_token next = sample_top_p(logits, 0.9);
            beams[i].tokens.push_back(next);
            beams[i].score += logf(get_prob(logits, next));
        }
    }

    return beams;
}
```

## 7. æ€»ç»“

ä»Šå¤©æˆ‘ä»¬æ·±å…¥å­¦ä¹ äº†é‡‡æ ·ç­–ç•¥ï¼š

âœ… **Temperature**: æ§åˆ¶ç¡®å®šæ€§ vs éšæœºæ€§
âœ… **Top-K/Top-P**: è¿‡æ»¤ä½è´¨é‡ token
âœ… **Mirostat**: è‡ªé€‚åº”æ§åˆ¶å›°æƒ‘åº¦
âœ… **é‡å¤æƒ©ç½š**: é¿å…æ— èŠçš„é‡å¤
âœ… **é‡‡æ ·é“¾**: ç»„åˆå¤šç§ç­–ç•¥

### æ¨èé…ç½®é€ŸæŸ¥

| åœºæ™¯ | Temperature | Top-P | Top-K | Repeat Penalty |
|------|-------------|-------|-------|----------------|
| **å¯¹è¯** | 0.7 | 0.9 | 40 | 1.1 |
| **ä»£ç ** | 0.2 | 0.5 | 20 | 1.05 |
| **åˆ›ä½œ** | 1.3 | 0.95 | 100 | 1.2 |
| **ç¿»è¯‘** | 0.3 | 0.7 | 30 | 1.0 |
| **æ‘˜è¦** | 0.5 | 0.8 | 50 | 1.15 |

## ä¸‹ä¸€æ­¥

æ˜å¤©æˆ‘ä»¬å°†å­¦ä¹  **Day 14: å®æˆ˜é¡¹ç›®ä¸æ€»ç»“**ï¼š
- ä»é›¶æ­å»ºæ¨ç†æœåŠ¡
- llama-server æºç è§£æ
- OpenAI API å…¼å®¹å®ç°
- è¯¾ç¨‹æ€»ç»“ä¸è¿›é˜¶è·¯çº¿

---

**ç»ƒä¹ **ï¼š
1. å®ç°ä¸€ä¸ªé‡‡æ ·å™¨ï¼Œç»“åˆ Top-K å’Œ Mirostat
2. åˆ†æä¸åŒ temperature å¯¹è¾“å‡ºçš„å½±å“
3. è®¾è®¡é€‚åˆä½ çš„åº”ç”¨åœºæ™¯çš„é‡‡æ ·é…ç½®

ğŸ“š [Day 14: å®æˆ˜é¡¹ç›®ä¸æ€»ç»“](day14-tools-practice.md)
