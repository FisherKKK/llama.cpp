# Day 11: CPU åç«¯ä¸ SIMD ä¼˜åŒ–

## è¯¾ç¨‹ç›®æ ‡

æŒæ¡ CPU åç«¯çš„ä¼˜åŒ–æŠ€æœ¯ï¼š
- SIMDï¼ˆSingle Instruction Multiple Dataï¼‰åŸç†
- AVX2/AVX-512 ä¼˜åŒ–
- ARM NEON ä¼˜åŒ–
- çŸ©é˜µä¹˜æ³•ä¼˜åŒ–å†…æ ¸
- é‡åŒ–è®¡ç®—åŠ é€Ÿ

## 1. SIMD åŸºç¡€

### 1.1 ä»€ä¹ˆæ˜¯ SIMDï¼Ÿ

**æ ‡é‡è®¡ç®—**ï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰ï¼š
```cpp
// ä¸€æ¬¡å¤„ç†ä¸€ä¸ªå…ƒç´ 
for (int i = 0; i < n; i++) {
    c[i] = a[i] + b[i];
}
// 4 æ¬¡åŠ æ³•éœ€è¦ 4 ä¸ª CPU å‘¨æœŸ
```

**SIMD è®¡ç®—**ï¼š
```cpp
// ä¸€æ¬¡å¤„ç†å¤šä¸ªå…ƒç´ 
__m256 va = _mm256_loadu_ps(&a[i]);     // åŠ è½½ 8 ä¸ª float
__m256 vb = _mm256_loadu_ps(&b[i]);     // åŠ è½½ 8 ä¸ª float
__m256 vc = _mm256_add_ps(va, vb);      // åŒæ—¶è®¡ç®— 8 ä¸ªåŠ æ³•
_mm256_storeu_ps(&c[i], vc);            // å­˜å‚¨ 8 ä¸ª float

// 8 æ¬¡åŠ æ³•åªéœ€ 1 ä¸ª CPU å‘¨æœŸ â†’ 8x åŠ é€Ÿ
```

### 1.2 ä¸»è¦ SIMD æŒ‡ä»¤é›†

| æŒ‡ä»¤é›† | å¯„å­˜å™¨å®½åº¦ | float æ•°é‡ | å¹³å° |
|--------|-----------|-----------|------|
| **SSE** | 128-bit | 4 | x86 (è€) |
| **AVX** | 256-bit | 8 | x86 (ç°ä»£) |
| **AVX2** | 256-bit | 8 + æ•´æ•° | x86 (æ¨è) |
| **AVX-512** | 512-bit | 16 | x86 (æœåŠ¡å™¨) |
| **NEON** | 128-bit | 4 | ARM (æ‰‹æœº/Mac) |
| **SVE** | å¯å˜ | å¯å˜ | ARM (æœåŠ¡å™¨) |

## 2. AVX2 å‘é‡åŠ æ³•ç¤ºä¾‹

### 2.1 æ ‡é‡ç‰ˆæœ¬

```c
// ä½ç½®ï¼šggml/src/ggml-cpu/vec-dot.c
void ggml_vec_add_f32(int n, float * z, const float * x, const float * y) {
    for (int i = 0; i < n; i++) {
        z[i] = x[i] + y[i];
    }
}
// æ€§èƒ½: ~0.25 GFLOPS
```

### 2.2 AVX2 ç‰ˆæœ¬

```c
// ä½ç½®ï¼šggml/src/ggml-cpu/vec-dot.c:256
void ggml_vec_add_f32_avx2(int n, float * z, const float * x, const float * y) {
    int i = 0;

    // å¤„ç† 32 ä¸ªå…ƒç´ ä¸ºä¸€ç»„ï¼ˆAVX2 å¯ä»¥åŒæ—¶å¤„ç† 8 ä¸ª floatï¼‰
    for (; i + 32 <= n; i += 32) {
        // åŠ è½½ 8 ä¸ª float Ã— 4 = 32 ä¸ªå…ƒç´ 
        __m256 x0 = _mm256_loadu_ps(x + i);
        __m256 x1 = _mm256_loadu_ps(x + i + 8);
        __m256 x2 = _mm256_loadu_ps(x + i + 16);
        __m256 x3 = _mm256_loadu_ps(x + i + 24);

        __m256 y0 = _mm256_loadu_ps(y + i);
        __m256 y1 = _mm256_loadu_ps(y + i + 8);
        __m256 y2 = _mm256_loadu_ps(y + i + 16);
        __m256 y3 = _mm256_loadu_ps(y + i + 24);

        // å‘é‡åŠ æ³•
        __m256 z0 = _mm256_add_ps(x0, y0);
        __m256 z1 = _mm256_add_ps(x1, y1);
        __m256 z2 = _mm256_add_ps(x2, y2);
        __m256 z3 = _mm256_add_ps(x3, y3);

        // å­˜å‚¨ç»“æœ
        _mm256_storeu_ps(z + i, z0);
        _mm256_storeu_ps(z + i + 8, z1);
        _mm256_storeu_ps(z + i + 16, z2);
        _mm256_storeu_ps(z + i + 24, z3);
    }

    // å¤„ç†å‰©ä½™å…ƒç´ 
    for (; i < n; i++) {
        z[i] = x[i] + y[i];
    }
}
// æ€§èƒ½: ~2.0 GFLOPS â†’ 8x åŠ é€Ÿ
```

## 3. çŸ©é˜µä¹˜æ³•ä¼˜åŒ–

### 3.1 æœ´ç´ å®ç°

```c
void matmul_naive(int M, int N, int K,
                  const float * A,  // [M, K]
                  const float * B,  // [K, N]
                  float * C) {      // [M, N]
    for (int i = 0; i < M; i++) {
        for (int j = 0; j < N; j++) {
            float sum = 0.0f;
            for (int k = 0; k < K; k++) {
                sum += A[i * K + k] * B[k * N + j];
            }
            C[i * N + j] = sum;
        }
    }
}
// æ€§èƒ½: ~5 GFLOPS
// é—®é¢˜: ç¼“å­˜æœªå‘½ä¸­ã€æ—  SIMD
```

### 3.2 åˆ†å— + AVX2 ä¼˜åŒ–

```c
// ä½ç½®ï¼šggml/src/ggml-cpu/ggml-cpu.c:2847
void ggml_compute_forward_mul_mat_f32(
    const struct ggml_compute_params * params,
    struct ggml_tensor * dst) {

    const struct ggml_tensor * src0 = dst->src[0];  // A
    const struct ggml_tensor * src1 = dst->src[1];  // B

    const int M = src0->ne[1];
    const int N = src1->ne[1];
    const int K = src0->ne[0];

    // åˆ†å—å¤§å°ï¼ˆé’ˆå¯¹ L1 ç¼“å­˜ä¼˜åŒ–ï¼‰
    const int MC = 128;   // M æ–¹å‘
    const int NC = 4096;  // N æ–¹å‘
    const int KC = 512;   // K æ–¹å‘

    for (int ic = 0; ic < M; ic += MC) {
        const int mc = MIN(MC, M - ic);

        for (int jc = 0; jc < N; jc += NC) {
            const int nc = MIN(NC, N - jc);

            for (int pc = 0; pc < K; pc += KC) {
                const int kc = MIN(KC, K - pc);

                // å¾®å†…æ ¸ï¼šAVX2 ä¼˜åŒ–çš„å°çŸ©é˜µä¹˜æ³•
                matmul_kernel_avx2(
                    mc, nc, kc,
                    src0->data + ic * K + pc,
                    src1->data + pc * N + jc,
                    dst->data + ic * N + jc);
            }
        }
    }
}

// å¾®å†…æ ¸å®ç°
static void matmul_kernel_avx2(
    int M, int N, int K,
    const float * A,
    const float * B,
    float * C) {

    for (int i = 0; i < M; i++) {
        for (int j = 0; j < N; j += 8) {  // æ¯æ¬¡å¤„ç† 8 åˆ—
            __m256 sum = _mm256_setzero_ps();

            for (int k = 0; k < K; k++) {
                __m256 a = _mm256_set1_ps(A[i * K + k]);     // å¹¿æ’­ A å…ƒç´ 
                __m256 b = _mm256_loadu_ps(&B[k * N + j]);   // åŠ è½½ B çš„ 8 ä¸ªå…ƒç´ 
                sum = _mm256_fmadd_ps(a, b, sum);            // FMA: sum += a * b
            }

            // ç´¯åŠ åˆ° C
            __m256 c = _mm256_loadu_ps(&C[i * N + j]);
            c = _mm256_add_ps(c, sum);
            _mm256_storeu_ps(&C[i * N + j], c);
        }
    }
}
// æ€§èƒ½: ~50 GFLOPS â†’ 10x åŠ é€Ÿ
```

**ä¼˜åŒ–æŠ€å·§**ï¼š
1. **åˆ†å—**ï¼šåˆ©ç”¨ L1/L2 ç¼“å­˜
2. **FMA**ï¼šèåˆä¹˜åŠ æŒ‡ä»¤
3. **å¾ªç¯å±•å¼€**ï¼šå‡å°‘åˆ†æ”¯
4. **å‘é‡åŒ–**ï¼šAVX2 åŒæ—¶å¤„ç† 8 ä¸ªå…ƒç´ 

## 4. é‡åŒ–çŸ©é˜µä¹˜æ³•

### 4.1 Q4_0 æ ¼å¼

```c
// Q4_0: 32 ä¸ª float å‹ç¼©åˆ° 18 å­—èŠ‚
typedef struct {
    ggml_fp16_t d;        // ç¼©æ”¾å› å­ (2 å­—èŠ‚)
    uint8_t qs[16];       // é‡åŒ–å€¼ (16 å­—èŠ‚, æ¯ä¸ª 4-bit)
} block_q4_0;

// 32 ä¸ª float (128 å­—èŠ‚) â†’ 18 å­—èŠ‚
// å‹ç¼©æ¯”: 7.1x
```

### 4.2 Q4_0 ç‚¹ç§¯ï¼ˆAVX2ï¼‰

```c
// ä½ç½®ï¼šggml/src/ggml-quants.c:1234
void ggml_vec_dot_q4_0_q8_0_avx2(int n, float * s, const void * vx, const void * vy) {
    const block_q4_0 * restrict x = vx;
    const block_q8_0 * restrict y = vy;

    __m256 acc = _mm256_setzero_ps();

    // æ¯æ¬¡å¤„ç†ä¸€ä¸ªå— (32 ä¸ªå…ƒç´ )
    const int nb = n / 32;
    for (int i = 0; i < nb; i++) {
        // 1. åé‡åŒ– x (4-bit â†’ float)
        __m256i qx = _mm256_loadu_si256((const __m256i *)x[i].qs);

        // åˆ†ç¦»ä½ 4 ä½å’Œé«˜ 4 ä½
        __m256i qx_lo = _mm256_and_si256(qx, _mm256_set1_epi8(0x0F));
        __m256i qx_hi = _mm256_and_si256(_mm256_srli_epi16(qx, 4), _mm256_set1_epi8(0x0F));

        // è½¬æ¢ä¸º int8
        qx_lo = _mm256_sub_epi8(qx_lo, _mm256_set1_epi8(8));
        qx_hi = _mm256_sub_epi8(qx_hi, _mm256_set1_epi8(8));

        // 2. åŠ è½½ y (int8)
        __m256i qy_lo = _mm256_loadu_si256((const __m256i *)&y[i].qs[0]);
        __m256i qy_hi = _mm256_loadu_si256((const __m256i *)&y[i].qs[16]);

        // 3. int8 ä¹˜æ³•
        __m256i p_lo = _mm256_maddubs_epi16(qx_lo, qy_lo);  // 16 ä¸ª int16
        __m256i p_hi = _mm256_maddubs_epi16(qx_hi, qy_hi);

        // 4. ç´¯åŠ 
        __m256i p = _mm256_add_epi16(p_lo, p_hi);
        __m256i sum = _mm256_madd_epi16(p, _mm256_set1_epi16(1));  // 8 ä¸ª int32

        // 5. è½¬æ¢ä¸º float å¹¶ç¼©æ”¾
        __m256 d = _mm256_set1_ps(GGML_FP16_TO_FP32(x[i].d) * GGML_FP16_TO_FP32(y[i].d));
        __m256 pf = _mm256_cvtepi32_ps(sum);
        acc = _mm256_fmadd_ps(d, pf, acc);
    }

    // æ°´å¹³æ±‚å’Œ
    *s = hsum_float_8(acc);
}
// æ€§èƒ½: ~80 GFLOPS (Q4_0 vs F32)
// å†…å­˜å¸¦å®½: 7x å‡å°‘
```

## 5. ARM NEON ä¼˜åŒ–

### 5.1 NEON å‘é‡åŠ æ³•

```c
// ä½ç½®ï¼šggml/src/ggml-cpu/vec-dot.c:789
void ggml_vec_add_f32_neon(int n, float * z, const float * x, const float * y) {
    int i = 0;

    // å¤„ç† 16 ä¸ªå…ƒç´ ä¸ºä¸€ç»„
    for (; i + 16 <= n; i += 16) {
        float32x4_t x0 = vld1q_f32(x + i);
        float32x4_t x1 = vld1q_f32(x + i + 4);
        float32x4_t x2 = vld1q_f32(x + i + 8);
        float32x4_t x3 = vld1q_f32(x + i + 12);

        float32x4_t y0 = vld1q_f32(y + i);
        float32x4_t y1 = vld1q_f32(y + i + 4);
        float32x4_t y2 = vld1q_f32(y + i + 8);
        float32x4_t y3 = vld1q_f32(y + i + 12);

        float32x4_t z0 = vaddq_f32(x0, y0);
        float32x4_t z1 = vaddq_f32(x1, y1);
        float32x4_t z2 = vaddq_f32(x2, y2);
        float32x4_t z3 = vaddq_f32(x3, y3);

        vst1q_f32(z + i, z0);
        vst1q_f32(z + i + 4, z1);
        vst1q_f32(z + i + 8, z2);
        vst1q_f32(z + i + 12, z3);
    }

    // å¤„ç†å‰©ä½™å…ƒç´ 
    for (; i < n; i++) {
        z[i] = x[i] + y[i];
    }
}
```

### 5.2 NEON vs AVX2 å¯¹æ¯”

| ç‰¹æ€§ | ARM NEON | x86 AVX2 |
|------|----------|----------|
| **å¯„å­˜å™¨å®½åº¦** | 128-bit | 256-bit |
| **float æ•°é‡** | 4 | 8 |
| **int8 ä¹˜æ³•** | vmlal_s8 | _mm256_maddubs_epi16 |
| **FMA** | vfmaq_f32 (ARMv8.2+) | _mm256_fmadd_ps |
| **æ€§èƒ½** | ~20 GFLOPS | ~40 GFLOPS |
| **å¹³å°** | Mac M1/M2, æ‰‹æœº | Intel/AMD CPU |

## 6. æ€§èƒ½è°ƒä¼˜æŠ€å·§

### 6.1 ç¼–è¯‘å™¨ä¼˜åŒ–æ ‡å¿—

```bash
# GCC/Clang
-O3                      # æœ€é«˜ä¼˜åŒ–çº§åˆ«
-march=native            # é’ˆå¯¹å½“å‰ CPU ä¼˜åŒ–
-mavx2                   # å¯ç”¨ AVX2
-mfma                    # å¯ç”¨ FMA æŒ‡ä»¤
-ffast-math              # å¿«é€Ÿæ•°å­¦ï¼ˆç‰ºç‰²ä¸€äº›ç²¾åº¦ï¼‰

# å®Œæ•´ç¤ºä¾‹
gcc -O3 -march=native -mavx2 -mfma -ffast-math \
    -o ggml ggml.c -lm -lpthread
```

### 6.2 æ€§èƒ½åˆ†æ

```cpp
#include <chrono>

void benchmark_operation() {
    auto start = std::chrono::high_resolution_clock::now();

    // æ‰§è¡Œæ“ä½œ
    ggml_vec_dot_f32(n, result, x, y);

    auto end = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);

    // è®¡ç®— GFLOPS
    double ops = 2.0 * n;  // n æ¬¡ä¹˜æ³• + n æ¬¡åŠ æ³•
    double gflops = ops / (duration.count() * 1e3);

    printf("Performance: %.2f GFLOPS\n", gflops);
}
```

### 6.3 å†…å­˜å¯¹é½

```c
// ç¡®ä¿æ•°æ®å¯¹é½åˆ° 32 å­—èŠ‚ï¼ˆAVX2ï¼‰
#define ALIGNED_32 __attribute__((aligned(32)))

// åˆ†é…å¯¹é½å†…å­˜
float * data = (float *)aligned_alloc(32, n * sizeof(float));

// ä½¿ç”¨å¯¹é½åŠ è½½ï¼ˆæ›´å¿«ï¼‰
__m256 v = _mm256_load_ps(data);  // è€Œé _mm256_loadu_ps
```

## 7. å®æˆ˜ï¼šä¼˜åŒ–è‡ªå·±çš„ä»£ç 

### 7.1 å‘é‡åŒ– ReLU

```c
// æ ‡é‡ç‰ˆæœ¬
void relu_scalar(int n, float * x) {
    for (int i = 0; i < n; i++) {
        if (x[i] < 0) x[i] = 0;
    }
}

// AVX2 ç‰ˆæœ¬
void relu_avx2(int n, float * x) {
    __m256 zero = _mm256_setzero_ps();

    for (int i = 0; i + 8 <= n; i += 8) {
        __m256 v = _mm256_loadu_ps(x + i);
        v = _mm256_max_ps(v, zero);  // max(v, 0)
        _mm256_storeu_ps(x + i, v);
    }

    // å‰©ä½™å…ƒç´ 
    for (int i = n & ~7; i < n; i++) {
        if (x[i] < 0) x[i] = 0;
    }
}
```

### 7.2 å‘é‡åŒ– Softmax

```c
void softmax_avx2(int n, float * x) {
    // 1. æ‰¾æœ€å¤§å€¼
    __m256 max_vec = _mm256_set1_ps(-INFINITY);
    for (int i = 0; i + 8 <= n; i += 8) {
        __m256 v = _mm256_loadu_ps(x + i);
        max_vec = _mm256_max_ps(max_vec, v);
    }
    float max_val = hmax_f32_8(max_vec);

    // 2. è®¡ç®— exp å¹¶ç´¯åŠ 
    __m256 max_bc = _mm256_set1_ps(max_val);
    __m256 sum_vec = _mm256_setzero_ps();

    for (int i = 0; i + 8 <= n; i += 8) {
        __m256 v = _mm256_loadu_ps(x + i);
        v = _mm256_sub_ps(v, max_bc);           // x - max
        v = _mm256_exp_ps(v);                   // exp(x - max)
        sum_vec = _mm256_add_ps(sum_vec, v);
        _mm256_storeu_ps(x + i, v);
    }
    float sum = hsum_f32_8(sum_vec);

    // 3. å½’ä¸€åŒ–
    __m256 sum_bc = _mm256_set1_ps(sum);
    for (int i = 0; i + 8 <= n; i += 8) {
        __m256 v = _mm256_loadu_ps(x + i);
        v = _mm256_div_ps(v, sum_bc);
        _mm256_storeu_ps(x + i, v);
    }
}
```

## 8. æ€»ç»“

ä»Šå¤©æˆ‘ä»¬å­¦ä¹ äº† CPU åç«¯ä¼˜åŒ–ï¼š

âœ… **SIMD åŸºç¡€**ï¼šAVX2/NEON å‘é‡åŒ–
âœ… **çŸ©é˜µä¹˜æ³•**ï¼šåˆ†å— + å¾®å†…æ ¸ä¼˜åŒ–
âœ… **é‡åŒ–åŠ é€Ÿ**ï¼šQ4_0 SIMD å®ç°
âœ… **ARM ä¼˜åŒ–**ï¼šNEON æŒ‡ä»¤é›†
âœ… **æ€§èƒ½è°ƒä¼˜**ï¼šç¼–è¯‘å™¨ä¼˜åŒ–ã€å¯¹é½ã€Benchmark

### å…³é”®è¦ç‚¹

1. **SIMD æ˜¯ CPU æ€§èƒ½çš„å…³é”®**ï¼š8-16x åŠ é€Ÿ
2. **åˆ†å—ä¼˜åŒ–ç¼“å­˜**ï¼šåˆ©ç”¨ L1/L2 ç¼“å­˜
3. **FMA æŒ‡ä»¤**ï¼šèåˆä¹˜åŠ æå‡æ€§èƒ½
4. **é‡åŒ– + SIMD**ï¼šå†…å­˜å¸¦å®½å’Œè®¡ç®—åŒé‡åŠ é€Ÿ

## ä¸‹ä¸€æ­¥

æ˜å¤©æˆ‘ä»¬å°†å­¦ä¹  **Day 12: GPU åç«¯å®ç°**ï¼š
- CUDA ç¼–ç¨‹åŸºç¡€
- cuBLAS é›†æˆ
- è‡ªå®šä¹‰ CUDA å†…æ ¸
- Metal/Vulkan å¯¹æ¯”

---

**ç»ƒä¹ **ï¼š
1. å®ç°ä¸€ä¸ª AVX2 ä¼˜åŒ–çš„å‘é‡ç‚¹ç§¯
2. å¯¹æ¯”æ ‡é‡å’Œ SIMD ç‰ˆæœ¬çš„æ€§èƒ½å·®å¼‚
3. ä½¿ç”¨ perf åˆ†æä½ çš„ä»£ç ç“¶é¢ˆ

ğŸ“š [Day 12: GPU åç«¯å®ç°](day12-gpu-backend.md)
