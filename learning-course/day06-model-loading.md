# Day 6: æ¨¡å‹åŠ è½½ä¸æƒé‡ç®¡ç†

## è¯¾ç¨‹ç›®æ ‡

æ·±å…¥ç†è§£ llama.cpp çš„æ¨¡å‹åŠ è½½æµç¨‹ï¼š
- ä» GGUF æ–‡ä»¶åˆ° llama_model ç»“æ„
- æ¶æ„è¯†åˆ«ä¸åˆå§‹åŒ–
- æƒé‡æ˜ å°„ä¸ç®¡ç†
- GPU åˆ†å±‚ offload
- å†…å­˜ä¼˜åŒ–ç­–ç•¥

## 1. æ¨¡å‹åŠ è½½å®Œæ•´æµç¨‹

### 1.1 æµç¨‹æ¦‚è§ˆ

```
ç”¨æˆ·è°ƒç”¨
llama_model_load_from_file("model.gguf", params)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. æ‰“å¼€ GGUF æ–‡ä»¶                        â”‚
â”‚    llama_model_loader ml(fname)          â”‚
â”‚    â€¢ è§£ææ–‡ä»¶å¤´                          â”‚
â”‚    â€¢ è¯»å–å…ƒæ•°æ®                          â”‚
â”‚    â€¢ å»ºç«‹å¼ é‡ç´¢å¼•                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. è¯†åˆ«æ¨¡å‹æ¶æ„                          â”‚
â”‚    const auto arch = ml.get_arch()       â”‚
â”‚    â€¢ è¯»å– "general.architecture"         â”‚
â”‚    â€¢ åŒ¹é…æ¶æ„æšä¸¾ (LLM_ARCH_LLAMA)       â”‚
â”‚    â€¢ åŠ è½½æ¶æ„ç‰¹å®šçš„é”®æ˜ å°„                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. åŠ è½½è¶…å‚æ•°                            â”‚
â”‚    llama_hparams hparams                 â”‚
â”‚    â€¢ n_vocab, n_embd, n_layer            â”‚
â”‚    â€¢ n_head, n_head_kv                   â”‚
â”‚    â€¢ RoPE å‚æ•°                           â”‚
â”‚    â€¢ å½’ä¸€åŒ–å‚æ•°                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. åˆå§‹åŒ– llama_model ç»“æ„               â”‚
â”‚    model = new llama_model()             â”‚
â”‚    model.arch = arch                     â”‚
â”‚    model.hparams = hparams               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. åˆ›å»ºå¼ é‡éª¨æ¶                          â”‚
â”‚    llm_load_tensors()                    â”‚
â”‚    â€¢ æ ¹æ®æ¶æ„åˆ›å»ºæ‰€æœ‰å±‚çš„å¼ é‡            â”‚
â”‚    â€¢ token_embd, output, norm            â”‚
â”‚    â€¢ 32å±‚ Ã— (attn + ffn)                 â”‚
â”‚    â€¢ ä¸åˆ†é…æ•°æ®ï¼Œåªè®¾ç½®ç»´åº¦              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. åˆ†é…åç«¯ç¼“å†²åŒº                        â”‚
â”‚    llama_backend_init()                  â”‚
â”‚    â€¢ CPU åç«¯ï¼šmalloc/mmap               â”‚
â”‚    â€¢ GPU åç«¯ï¼šcudaMalloc/Metal          â”‚
â”‚    â€¢ æ ¹æ® n_gpu_layers åˆ†é…              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. åŠ è½½æƒé‡æ•°æ®                          â”‚
â”‚    ml.load_all_data()                    â”‚
â”‚    â€¢ ä» GGUF è¯»å–é‡åŒ–æ•°æ®                â”‚
â”‚    â€¢ æ‹·è´åˆ°å¯¹åº”çš„åç«¯ç¼“å†²åŒº              â”‚
â”‚    â€¢ GPU å¼ é‡ï¼šCPU â†’ GPU ä¼ è¾“            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. åˆå§‹åŒ–è¯è¡¨                            â”‚
â”‚    llama_vocab_init()                    â”‚
â”‚    â€¢ ä»å…ƒæ•°æ®è¯»å– tokens                 â”‚
â”‚    â€¢ æ„å»º token â†” ID æ˜ å°„                â”‚
â”‚    â€¢ åˆå§‹åŒ– tokenizer                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
           è¿”å› model
```

## 2. æ ¸å¿ƒä»£ç è§£æ

### 2.1 llama_model_load_from_fileï¼ˆå…¥å£ï¼‰

```cpp
// ä½ç½®ï¼šsrc/llama-model.cpp:16234
struct llama_model * llama_model_load_from_file(
    const char * path_model,
    struct llama_model_params params) {

    // 1. åˆå§‹åŒ–åç«¯ç³»ç»Ÿ
    ggml_backend_load_all();

    // 2. åˆ›å»ºæ¨¡å‹å¯¹è±¡
    llama_model * model = new llama_model();

    // 3. åˆ›å»ºåŠ è½½å™¨
    llama_model_loader ml(path_model, params);

    // 4. è¯†åˆ«æ¶æ„
    ml.init_mappings();
    model->arch = ml.get_arch();

    // 5. åŠ è½½è¶…å‚æ•°
    llm_load_hparams(ml, model->hparams);

    // 6. åŠ è½½è¯è¡¨
    llm_load_vocab(ml, model->vocab);

    // 7. åŠ è½½å¼ é‡
    llm_load_tensors(ml, model, params);

    // 8. è¿”å›
    return model;
}
```

### 2.2 æ¶æ„è¯†åˆ«

```cpp
// ä½ç½®ï¼šsrc/llama-model-loader.cpp:456
llm_arch llama_model_loader::get_arch() const {
    // ä»å…ƒæ•°æ®è¯»å–æ¶æ„å­—ç¬¦ä¸²
    const std::string arch_name = get_arch_name();

    // æ˜ å°„åˆ°æšä¸¾
    static const std::map<std::string, llm_arch> arch_map = {
        { "llama",    LLM_ARCH_LLAMA },
        { "mistral",  LLM_ARCH_MISTRAL },
        { "qwen",     LLM_ARCH_QWEN },
        { "gemma",    LLM_ARCH_GEMMA },
        { "phi",      LLM_ARCH_PHI },
        // ... 120+ æ¶æ„
    };

    auto it = arch_map.find(arch_name);
    if (it == arch_map.end()) {
        throw std::runtime_error("unknown architecture: " + arch_name);
    }

    return it->second;
}

std::string llama_model_loader::get_arch_name() const {
    return get_metadata_string("general.architecture");
}
```

### 2.3 åŠ è½½è¶…å‚æ•°

```cpp
// ä½ç½®ï¼šsrc/llama-hparams.cpp:78
static void llm_load_hparams(
    llama_model_loader & ml,
    llama_hparams & hparams) {

    const auto arch = ml.get_arch();

    // åŸºç¡€å‚æ•°ï¼ˆæ‰€æœ‰æ¶æ„é€šç”¨ï¼‰
    ml.get_key(LLM_KV_VOCAB_SIZE,        hparams.n_vocab);
    ml.get_key(LLM_KV_EMBEDDING_LENGTH,  hparams.n_embd);
    ml.get_key(LLM_KV_BLOCK_COUNT,       hparams.n_layer);
    ml.get_key(LLM_KV_ATTENTION_HEAD_COUNT, hparams.n_head);

    // KV å¤´æ•°ï¼ˆå¤šæŸ¥è¯¢æ³¨æ„åŠ›ï¼‰
    if (!ml.get_key(LLM_KV_ATTENTION_HEAD_COUNT_KV, hparams.n_head_kv, false)) {
        hparams.n_head_kv = hparams.n_head;  // é»˜è®¤ä¸ Q ç›¸åŒ
    }

    // FFN å‚æ•°
    ml.get_key(LLM_KV_FEED_FORWARD_LENGTH, hparams.n_ff);

    // RoPE å‚æ•°
    ml.get_key(LLM_KV_ROPE_DIMENSION_COUNT, hparams.n_rot);
    ml.get_key(LLM_KV_ROPE_FREQ_BASE,       hparams.rope_freq_base, false);

    // å½’ä¸€åŒ–å‚æ•°
    ml.get_key(LLM_KV_ATTENTION_LAYERNORM_RMS_EPS, hparams.f_norm_rms_eps);

    // æ¶æ„ç‰¹å®šå‚æ•°
    switch (arch) {
        case LLM_ARCH_LLAMA:
            // LLaMA ç‰¹å®š
            break;

        case LLM_ARCH_MISTRAL:
            // Mistral æ”¯æŒ Sliding Window Attention
            ml.get_key(LLM_KV_ATTENTION_SLIDING_WINDOW, hparams.n_swa, false);
            break;

        // ... å…¶ä»–æ¶æ„
    }

    // æ‰“å°åŠ è½½çš„å‚æ•°
    LLAMA_LOG_INFO("n_vocab    = %u\n", hparams.n_vocab);
    LLAMA_LOG_INFO("n_embd     = %u\n", hparams.n_embd);
    LLAMA_LOG_INFO("n_layer    = %u\n", hparams.n_layer);
    LLAMA_LOG_INFO("n_head     = %u\n", hparams.n_head);
    LLAMA_LOG_INFO("n_head_kv  = %u\n", hparams.n_head_kv);
}
```

### 2.4 åˆ›å»ºå¼ é‡éª¨æ¶

```cpp
// ä½ç½®ï¼šsrc/llama-model.cpp:3847
static bool llm_load_tensors(
    llama_model_loader & ml,
    llama_model & model,
    const llama_model_params & params) {

    const auto & hparams = model.hparams;
    const auto arch = model.arch;

    // 1. åˆ›å»ºè¾“å…¥åµŒå…¥å±‚
    model.tok_embd = ml.create_tensor(
        "token_embd.weight",
        {hparams.n_embd, hparams.n_vocab},
        GGML_TYPE_F32);

    // 2. åˆ›å»ºè¾“å‡ºå±‚
    model.output = ml.create_tensor(
        "output.weight",
        {hparams.n_embd, hparams.n_vocab},
        GGML_TYPE_F32);

    // 3. åˆ›å»ºæœ€ç»ˆå½’ä¸€åŒ–å±‚
    model.output_norm = ml.create_tensor(
        "output_norm.weight",
        {hparams.n_embd},
        GGML_TYPE_F32);

    // 4. åˆ›å»ºæ‰€æœ‰ Transformer å±‚
    model.layers.resize(hparams.n_layer);

    for (uint32_t i = 0; i < hparams.n_layer; i++) {
        auto & layer = model.layers[i];

        // æ³¨æ„åŠ›å±‚æƒé‡
        layer.attn_norm = ml.create_tensor(
            format("blk.%d.attn_norm.weight", i),
            {hparams.n_embd},
            GGML_TYPE_F32);

        layer.attn_q = ml.create_tensor(
            format("blk.%d.attn_q.weight", i),
            {hparams.n_embd, hparams.n_embd},
            GGML_TYPE_Q4_K);  // é‡åŒ–ç±»å‹

        layer.attn_k = ml.create_tensor(
            format("blk.%d.attn_k.weight", i),
            {hparams.n_embd, hparams.n_embd_k},  // KV å¤´å¯èƒ½ä¸åŒ
            GGML_TYPE_Q4_K);

        layer.attn_v = ml.create_tensor(
            format("blk.%d.attn_v.weight", i),
            {hparams.n_embd, hparams.n_embd_v},
            GGML_TYPE_Q4_K);

        layer.attn_output = ml.create_tensor(
            format("blk.%d.attn_output.weight", i),
            {hparams.n_embd, hparams.n_embd},
            GGML_TYPE_Q4_K);

        // FFN å±‚æƒé‡
        layer.ffn_norm = ml.create_tensor(
            format("blk.%d.ffn_norm.weight", i),
            {hparams.n_embd},
            GGML_TYPE_F32);

        layer.ffn_gate = ml.create_tensor(
            format("blk.%d.ffn_gate.weight", i),
            {hparams.n_embd, hparams.n_ff},
            GGML_TYPE_Q4_K);

        layer.ffn_up = ml.create_tensor(
            format("blk.%d.ffn_up.weight", i),
            {hparams.n_embd, hparams.n_ff},
            GGML_TYPE_Q4_K);

        layer.ffn_down = ml.create_tensor(
            format("blk.%d.ffn_down.weight", i),
            {hparams.n_ff, hparams.n_embd},
            GGML_TYPE_Q4_K);
    }

    return true;
}
```

## 3. GPU åˆ†å±‚ Offload

### 3.1 Offload ç­–ç•¥

```cpp
// ä½ç½®ï¼šsrc/llama-model.cpp:4821
static void llm_load_tensors_offload(
    llama_model & model,
    const llama_model_params & params) {

    const int n_gpu = params.n_gpu_layers;
    const int n_layer = model.hparams.n_layer;

    if (n_gpu == 0) {
        // çº¯ CPU æ¨¡å¼
        for (auto & tensor : model.tensors) {
            tensor->backend = GGML_BACKEND_CPU;
        }
        return;
    }

    // å†³å®šå“ªäº›å±‚åœ¨ GPU ä¸Š
    int layer_gpu_count = std::min(n_gpu, n_layer);

    LLAMA_LOG_INFO("offloading %d/%d layers to GPU\n",
                   layer_gpu_count, n_layer);

    // è¾“å…¥/è¾“å‡ºå±‚å§‹ç»ˆåœ¨ GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if (n_gpu > 0) {
        model.tok_embd->backend = GGML_BACKEND_GPU;
        model.output->backend = GGML_BACKEND_GPU;
        model.output_norm->backend = GGML_BACKEND_GPU;
    }

    // åˆ†é… Transformer å±‚
    for (int i = 0; i < n_layer; i++) {
        auto & layer = model.layers[i];

        if (i < layer_gpu_count) {
            // åœ¨ GPU ä¸Š
            layer.attn_q->backend = GGML_BACKEND_GPU;
            layer.attn_k->backend = GGML_BACKEND_GPU;
            layer.attn_v->backend = GGML_BACKEND_GPU;
            layer.attn_output->backend = GGML_BACKEND_GPU;
            layer.ffn_gate->backend = GGML_BACKEND_GPU;
            layer.ffn_up->backend = GGML_BACKEND_GPU;
            layer.ffn_down->backend = GGML_BACKEND_GPU;
        } else {
            // åœ¨ CPU ä¸Š
            layer.attn_q->backend = GGML_BACKEND_CPU;
            // ... å…¶ä»–å¼ é‡
        }
    }
}
```

### 3.2 å¤š GPU æ”¯æŒ

```cpp
// ä½ç½®ï¼šsrc/llama-model.cpp:5123
static void llm_load_tensors_multi_gpu(
    llama_model & model,
    const llama_model_params & params) {

    const int n_gpu = params.devices.size();
    const int n_layer = model.hparams.n_layer;

    if (n_gpu <= 1) {
        // å• GPUï¼Œä½¿ç”¨ç®€å•ç­–ç•¥
        llm_load_tensors_offload(model, params);
        return;
    }

    // å¤š GPU åˆ†å‰²ç­–ç•¥
    std::vector<int> layer_splits(n_gpu);

    if (params.split_mode == LLAMA_SPLIT_MODE_LAYER) {
        // æŒ‰å±‚åˆ†å‰²
        int layers_per_gpu = n_layer / n_gpu;
        for (int i = 0; i < n_gpu; i++) {
            layer_splits[i] = layers_per_gpu;
        }
        layer_splits[n_gpu - 1] += n_layer % n_gpu;  // ä½™æ•°ç»™æœ€åä¸€ä¸ªGPU

    } else if (params.split_mode == LLAMA_SPLIT_MODE_ROW) {
        // å¼ é‡å¹¶è¡Œï¼ˆæŒ‰è¡Œåˆ†å‰²çŸ©é˜µï¼‰
        for (int i = 0; i < n_layer; i++) {
            auto & layer = model.layers[i];

            // æ¯ä¸ª GPU è´Ÿè´£éƒ¨åˆ†åˆ—
            for (int gpu_id = 0; gpu_id < n_gpu; gpu_id++) {
                layer.attn_q_splits[gpu_id] = split_tensor_row(
                    layer.attn_q, gpu_id, n_gpu);
            }
        }
    }

    // åˆ†é…å¼ é‡åˆ°ä¸åŒ GPU
    int current_layer = 0;
    for (int gpu_id = 0; gpu_id < n_gpu; gpu_id++) {
        ggml_backend_t backend = params.devices[gpu_id].backend;

        for (int i = 0; i < layer_splits[gpu_id]; i++) {
            auto & layer = model.layers[current_layer++];

            // è®¾ç½®åç«¯
            ggml_backend_tensor_set_backend(layer.attn_q, backend);
            // ... å…¶ä»–å¼ é‡
        }
    }
}
```

## 4. å†…å­˜ä¼˜åŒ–æŠ€å·§

### 4.1 ä½¿ç”¨ mmap

```cpp
// ä¼˜åŠ¿ï¼š
// â€¢ å»¶è¿ŸåŠ è½½ï¼šåªåŠ è½½è®¿é—®çš„é¡µé¢
// â€¢ å…±äº«å†…å­˜ï¼šå¤šè¿›ç¨‹å…±äº«åŒä¸€ä»½æ•°æ®
// â€¢ èŠ‚çœå†…å­˜ï¼šOS ç®¡ç†é¡µé¢ç¼“å­˜

llama_model_params params = llama_model_default_params();
params.use_mmap = true;  // å¯ç”¨ mmapï¼ˆé»˜è®¤ï¼‰

// å¦‚æœå†…å­˜å……è¶³ï¼Œå¯ä»¥é”å®šå†…å­˜é¡µï¼ˆé¿å…swapï¼‰
params.use_mlock = true;  // éœ€è¦è¶³å¤Ÿçš„ RAM
```

### 4.2 é‡åŒ–æ„ŸçŸ¥åŠ è½½

```cpp
// æ ¹æ®å¯ç”¨å†…å­˜é€‰æ‹©é‡åŒ–çº§åˆ«
size_t available_mem = get_available_memory();
size_t model_size_f16 = 14 * 1024 * 1024 * 1024;  // 7B æ¨¡å‹çº¦ 14GB (FP16)

if (available_mem < model_size_f16 * 0.5) {
    // å†…å­˜ä¸è¶³ï¼Œä½¿ç”¨ Q4_0
    fprintf(stderr, "Low memory, using Q4_0 quantization\n");
    // æç¤ºç”¨æˆ·é‡æ–°é‡åŒ–æ¨¡å‹
} else if (available_mem < model_size_f16) {
    // ä¸­ç­‰å†…å­˜ï¼Œä½¿ç”¨ Q4_K
    fprintf(stderr, "Medium memory, Q4_K recommended\n");
} else {
    // å……è¶³å†…å­˜ï¼Œå¯ä»¥ä½¿ç”¨ Q6_K æˆ– FP16
    fprintf(stderr, "Sufficient memory, using higher precision\n");
}
```

### 4.3 æ¸è¿›å¼åŠ è½½

```cpp
// å¯¹äºè¶…å¤§æ¨¡å‹ï¼Œåˆ†æ‰¹åŠ è½½
llama_model_params params = llama_model_default_params();
params.progress_callback = [](float progress, void * ctx) {
    printf("Loading: %.1f%%\r", progress * 100);
    fflush(stdout);
};

// é¢„åŠ è½½é‡è¦å±‚
params.n_gpu_layers = 16;  // å…ˆåŠ è½½å‰16å±‚åˆ°GPU
model = llama_model_load_from_file("model.gguf", params);

// åç»­å¯ä»¥åŠ¨æ€è°ƒæ•´
llama_model_offload_layers(model, 32);  // åŠ è½½æ›´å¤šå±‚
```

## 5. è°ƒè¯•ä¸éªŒè¯

### 5.1 éªŒè¯å¼ é‡å®Œæ•´æ€§

```cpp
void verify_model_tensors(const llama_model & model) {
    const auto & hparams = model.hparams;

    // æ£€æŸ¥åµŒå…¥å±‚
    assert(model.tok_embd != nullptr);
    assert(model.tok_embd->ne[0] == hparams.n_embd);
    assert(model.tok_embd->ne[1] == hparams.n_vocab);

    // æ£€æŸ¥æ¯ä¸€å±‚
    for (size_t i = 0; i < model.layers.size(); i++) {
        const auto & layer = model.layers[i];

        // æ£€æŸ¥æ³¨æ„åŠ›æƒé‡
        assert(layer.attn_q != nullptr);
        assert(layer.attn_k != nullptr);
        assert(layer.attn_v != nullptr);
        assert(layer.attn_output != nullptr);

        // æ£€æŸ¥ç»´åº¦
        assert(layer.attn_q->ne[0] == hparams.n_embd);
        assert(layer.attn_q->ne[1] == hparams.n_embd);

        // æ£€æŸ¥ FFN æƒé‡
        assert(layer.ffn_gate != nullptr);
        assert(layer.ffn_up != nullptr);
        assert(layer.ffn_down != nullptr);

        printf("Layer %zu: OK\n", i);
    }

    printf("Model tensors verified successfully!\n");
}
```

### 5.2 å†…å­˜ä½¿ç”¨ç»Ÿè®¡

```cpp
void print_memory_usage(const llama_model & model) {
    size_t total_size = 0;
    size_t gpu_size = 0;
    size_t cpu_size = 0;

    for (const auto & [name, tensor] : model.tensors) {
        size_t size = ggml_nbytes(tensor);
        total_size += size;

        if (tensor->backend == GGML_BACKEND_GPU) {
            gpu_size += size;
        } else {
            cpu_size += size;
        }
    }

    printf("Memory Usage:\n");
    printf("  Total: %.2f GB\n", total_size / (1024.0 * 1024 * 1024));
    printf("  GPU:   %.2f GB (%.1f%%)\n",
           gpu_size / (1024.0 * 1024 * 1024),
           100.0 * gpu_size / total_size);
    printf("  CPU:   %.2f GB (%.1f%%)\n",
           cpu_size / (1024.0 * 1024 * 1024),
           100.0 * cpu_size / total_size);
}
```

## 6. å®è·µç»ƒä¹ 

### ç»ƒä¹  1ï¼šåˆ†ææ¨¡å‹ç»“æ„
ç¼–å†™ä»£ç ç»Ÿè®¡ï¼š
- æ€»å‚æ•°é‡
- æ¯å±‚çš„å‚æ•°åˆ†å¸ƒ
- é‡åŒ–ç±»å‹ç»Ÿè®¡

### ç»ƒä¹  2ï¼šè‡ªå®šä¹‰åŠ è½½ç­–ç•¥
å®ç°æ ¹æ®å±‚é‡è¦æ€§çš„æ™ºèƒ½ offloadï¼š
- å‰å‡ å±‚å’Œåå‡ å±‚åœ¨ GPU
- ä¸­é—´å±‚åœ¨ CPU

### ç»ƒä¹  3ï¼šå†…å­˜é¢„ç®—
ç»™å®šå†…å­˜é™åˆ¶ï¼Œè®¡ç®—æœ€ä¼˜çš„ n_gpu_layers é…ç½®ã€‚

## 7. æ€»ç»“

ä»Šå¤©æˆ‘ä»¬å­¦ä¹ äº†æ¨¡å‹åŠ è½½çš„å®Œæ•´æµç¨‹ï¼š

âœ… **GGUF â†’ llama_model**ï¼šä»æ–‡ä»¶åˆ°å†…å­˜ç»“æ„
âœ… **æ¶æ„è¯†åˆ«**ï¼šæ”¯æŒ 120+ ç§æ¨¡å‹æ¶æ„
âœ… **GPU Offload**ï¼šçµæ´»çš„ CPU/GPU æ··åˆéƒ¨ç½²
âœ… **å†…å­˜ä¼˜åŒ–**ï¼šmmapã€é‡åŒ–ã€æ¸è¿›å¼åŠ è½½

### å…³é”®è¦ç‚¹

1. **å»¶è¿Ÿåˆ†é…**ï¼šå…ˆåˆ›å»ºéª¨æ¶ï¼ŒååŠ è½½æ•°æ®
2. **çµæ´» offload**ï¼šæ ¹æ®èµ„æºåŠ¨æ€è°ƒæ•´
3. **é‡åŒ–å‹å¥½**ï¼šæƒé‡ä¿æŒé‡åŒ–æ ¼å¼
4. **æ¶æ„é©±åŠ¨**ï¼šå…ƒæ•°æ®å†³å®šæ¨¡å‹ç»“æ„

## ä¸‹ä¸€æ­¥

æ˜å¤©æˆ‘ä»¬å°†å­¦ä¹  **Day 7: è®¡ç®—å›¾æ„å»ºä¸è°ƒåº¦**ï¼š
- llama_graph_builder å®ç°
- æ„å»º Transformer è®¡ç®—å›¾
- åç«¯è°ƒåº¦ç­–ç•¥
- æ€§èƒ½ä¼˜åŒ–æŠ€å·§

---

ğŸ“š [Day 7: è®¡ç®—å›¾æ„å»ºä¸è°ƒåº¦](day07-computation-graph.md)
