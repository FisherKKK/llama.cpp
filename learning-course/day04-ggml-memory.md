# Day 4: GGML å†…å­˜ç®¡ç†æœºåˆ¶

## è¯¾ç¨‹ç›®æ ‡

æ·±å…¥ç†è§£ GGML çš„å†…å­˜ç®¡ç†ï¼š
- å†…å­˜åˆ†é…å™¨ï¼ˆAllocatorï¼‰åŸç†
- ä¸Šä¸‹æ–‡ï¼ˆContextï¼‰å†…å­˜æ± 
- mmap æ–‡ä»¶æ˜ å°„æŠ€æœ¯
- åç«¯ç¼“å†²åŒºç®¡ç†
- å†…å­˜ä¼˜åŒ–ç­–ç•¥

## 1. GGML å†…å­˜ç®¡ç†æ¦‚è§ˆ

### 1.1 ä¸ºä»€ä¹ˆéœ€è¦è‡ªå®šä¹‰å†…å­˜ç®¡ç†ï¼Ÿ

GGML ä¸ä½¿ç”¨æ ‡å‡†çš„ `malloc/free`ï¼Œè€Œæ˜¯å®ç°äº†è‡ªå·±çš„å†…å­˜ç®¡ç†ç³»ç»Ÿï¼š

**åŸå› **ï¼š
1. **æ€§èƒ½**ï¼šå‡å°‘é¢‘ç¹çš„å†…å­˜åˆ†é…å¼€é”€
2. **å¯æ§æ€§**ï¼šç²¾ç¡®æ§åˆ¶å†…å­˜å¸ƒå±€å’Œç”Ÿå‘½å‘¨æœŸ
3. **ä¼˜åŒ–**ï¼šæ”¯æŒ mmapã€mlock ç­‰é«˜çº§ç‰¹æ€§
4. **è·¨å¹³å°**ï¼šç»Ÿä¸€çš„å†…å­˜ç®¡ç†æ¥å£

### 1.2 å†…å­˜ç®¡ç†å±‚æ¬¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ åº”ç”¨å±‚                                   â”‚
â”‚  ggml_new_tensor_*()                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GGML Context å±‚                         â”‚
â”‚  â€¢ å†…å­˜æ± ç®¡ç†                           â”‚
â”‚  â€¢ å¼ é‡åˆ†é…                             â”‚
â”‚  â€¢ å¯¹è±¡è¿½è¸ª                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backend Buffer å±‚                       â”‚
â”‚  â€¢ CPU ç¼“å†²åŒº                           â”‚
â”‚  â€¢ GPU ç¼“å†²åŒº                           â”‚
â”‚  â€¢ è·¨è®¾å¤‡ä¼ è¾“                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç³»ç»Ÿå±‚                                   â”‚
â”‚  â€¢ malloc/free (CPU)                    â”‚
â”‚  â€¢ cudaMalloc (GPU)                     â”‚
â”‚  â€¢ mmap (æ–‡ä»¶æ˜ å°„)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 2. GGML Contextï¼ˆä¸Šä¸‹æ–‡ï¼‰

### 2.1 Context ç»“æ„

```c
// ä½ç½®ï¼šggml/src/ggml.c:1823
struct ggml_context {
    size_t mem_size;           // å†…å­˜æ± æ€»å¤§å°
    void * mem_buffer;         // å†…å­˜æ± æŒ‡é’ˆ
    bool   mem_buffer_owned;   // æ˜¯å¦æ‹¥æœ‰å†…å­˜

    int    n_objects;          // å·²åˆ†é…å¯¹è±¡æ•°

    struct ggml_object * objects_begin;  // å¯¹è±¡é“¾è¡¨å¤´
    struct ggml_object * objects_end;    // å¯¹è±¡é“¾è¡¨å°¾

    struct ggml_scratch scratch;         // ä¸´æ—¶å†…å­˜åŒºåŸŸ
    struct ggml_scratch scratch_save;    // ä¿å­˜çš„ä¸´æ—¶å†…å­˜

    // å¯¹é½é…ç½®
    size_t alignment;
};
```

### 2.2 åˆå§‹åŒ– Context

```c
// ä½ç½®ï¼šggml/src/ggml.c:2847
struct ggml_context * ggml_init(struct ggml_init_params params) {
    // 1. é™æ€åˆå§‹åŒ–ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰
    ggml_critical_section_start();
    static bool is_first_call = true;
    if (is_first_call) {
        ggml_setup_op_has_task_pass();  // åˆå§‹åŒ–æ“ä½œè¡¨
        is_first_call = false;
    }
    ggml_critical_section_end();

    // 2. è®¡ç®—æ‰€éœ€å†…å­˜å¤§å°
    const size_t mem_size = params.mem_size;

    // å¯¹é½åˆ° GGML_MEM_ALIGN (16å­—èŠ‚)
    size_t ctx_size = GGML_OBJECT_SIZE;
    ctx_size = GGML_PAD(ctx_size, GGML_MEM_ALIGN);

    // 3. åˆ†é…ä¸Šä¸‹æ–‡ç»“æ„
    struct ggml_context * ctx = NULL;

    if (params.mem_buffer != NULL) {
        // ç”¨æˆ·æä¾›çš„ç¼“å†²åŒº
        ctx = (struct ggml_context *)(params.mem_buffer);
        ctx->mem_buffer_owned = false;
        ctx->mem_buffer = (char *)params.mem_buffer + ctx_size;
    } else {
        // è‡ªåŠ¨åˆ†é…
        ctx = (struct ggml_context *)malloc(ctx_size + mem_size);
        ctx->mem_buffer_owned = true;
        ctx->mem_buffer = (char *)ctx + ctx_size;
    }

    // 4. åˆå§‹åŒ–å­—æ®µ
    ctx->mem_size = mem_size;
    ctx->n_objects = 0;
    ctx->objects_begin = NULL;
    ctx->objects_end = NULL;
    ctx->scratch = (struct ggml_scratch) {
        .offs = 0,
        .size = 0,
        .data = NULL,
    };
    ctx->alignment = GGML_MEM_ALIGN;

    GGML_PRINT_DEBUG("ggml_init: context initialized with %zu bytes\n", mem_size);

    return ctx;
}
```

### 2.3 ä½¿ç”¨ç¤ºä¾‹

```c
// æ–¹å¼ 1: è‡ªåŠ¨åˆ†é…
struct ggml_init_params params = {
    .mem_size   = 128*1024*1024,  // 128 MB
    .mem_buffer = NULL,
    .no_alloc   = false,
};
struct ggml_context * ctx = ggml_init(params);

// æ–¹å¼ 2: ç”¨æˆ·æä¾›ç¼“å†²åŒº
void * buffer = malloc(128*1024*1024);
struct ggml_init_params params = {
    .mem_size   = 128*1024*1024,
    .mem_buffer = buffer,
    .no_alloc   = false,
};
struct ggml_context * ctx = ggml_init(params);

// æ–¹å¼ 3: å»¶è¿Ÿåˆ†é…ï¼ˆåªåˆ†é…å…ƒæ•°æ®ï¼‰
struct ggml_init_params params = {
    .mem_size   = 0,
    .mem_buffer = NULL,
    .no_alloc   = true,  // ä¸åˆ†é…æ•°æ®ï¼Œåªåˆ†é…ç»“æ„
};
struct ggml_context * ctx = ggml_init(params);
```

## 3. å¯¹è±¡åˆ†é…æœºåˆ¶

### 3.1 å¯¹è±¡ç»“æ„

```c
// ä½ç½®ï¼šggml/src/ggml.c:1811
struct ggml_object {
    size_t offs;               // åœ¨å†…å­˜æ± ä¸­çš„åç§»
    size_t size;               // å¯¹è±¡å¤§å°
    struct ggml_object * next; // é“¾è¡¨ä¸‹ä¸€ä¸ª
    enum ggml_object_type type;

    char padding[8];           // å¯¹é½å¡«å……
};

enum ggml_object_type {
    GGML_OBJECT_TYPE_TENSOR,
    GGML_OBJECT_TYPE_GRAPH,
    GGML_OBJECT_TYPE_WORK_BUFFER,
};
```

### 3.2 åˆ†é…å¼ é‡

```c
// ä½ç½®ï¼šggml/src/ggml.c:3124
static struct ggml_tensor * ggml_new_tensor_impl(
    struct ggml_context * ctx,
    enum ggml_type type,
    int n_dims,
    const int64_t * ne,
    struct ggml_tensor * view_src,
    size_t view_offs) {

    // 1. è®¡ç®—å¼ é‡ç»“æ„å¤§å°
    size_t size_needed = sizeof(struct ggml_tensor);
    size_needed = GGML_PAD(size_needed, GGML_MEM_ALIGN);

    // 2. è®¡ç®—æ•°æ®å¤§å°
    size_t data_size = ggml_row_size(type, ne[0]);
    for (int i = 1; i < n_dims; i++) {
        data_size *= ne[i];
    }
    data_size = GGML_PAD(data_size, GGML_MEM_ALIGN);

    // 3. åˆ†é…å¯¹è±¡å¤´
    struct ggml_object * obj_new = ggml_new_object(
        ctx,
        GGML_OBJECT_TYPE_TENSOR,
        size_needed + data_size
    );

    // 4. åˆå§‹åŒ–å¼ é‡
    struct ggml_tensor * result = (struct ggml_tensor *)((char *)ctx->mem_buffer + obj_new->offs);

    *result = (struct ggml_tensor) {
        .type = type,
        .backend = GGML_BACKEND_TYPE_CPU,
        .n_dims = n_dims,
        .ne = { 1, 1, 1, 1 },
        .nb = { 0, 0, 0, 0 },
        .op = GGML_OP_NONE,
        .op_params = { 0 },
        .flags = 0,
        .src = { NULL },
        .view_src = view_src,
        .view_offs = view_offs,
        .data = (view_src == NULL) ? (char *)result + size_needed : NULL,
        .name = { 0 },
        .extra = NULL,
    };

    // 5. è®¾ç½®ç»´åº¦å’Œæ­¥é•¿
    for (int i = 0; i < n_dims; i++) {
        result->ne[i] = ne[i];
    }

    result->nb[0] = ggml_type_size(type);
    for (int i = 1; i < GGML_MAX_DIMS; i++) {
        result->nb[i] = result->nb[i - 1] * result->ne[i - 1];
    }

    return result;
}
```

### 3.3 å†…å­˜å¸ƒå±€ç¤ºä¾‹

```
Context å†…å­˜æ± å¸ƒå±€ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Object 1: Tensor                       â”‚  offs=0
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ struct ggml_tensor (120 bytes)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Tensor data (aligned)            â”‚ â”‚
â”‚  â”‚ [4096 x 4096 x 4 bytes]          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Object 2: Tensor                       â”‚  offs=67108992
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ struct ggml_tensor               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Tensor data                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Object 3: Graph                        â”‚
â”‚  ...                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Free space                             â”‚
â”‚  (æœªä½¿ç”¨çš„å†…å­˜æ± ç©ºé—´)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 4. Scratch Memoryï¼ˆä¸´æ—¶å†…å­˜ï¼‰

### 4.1 Scratch æœºåˆ¶

Scratch æ˜¯ä¸€å—å¯é‡ç”¨çš„ä¸´æ—¶å†…å­˜åŒºåŸŸï¼Œç”¨äºå­˜å‚¨ä¸­é—´è®¡ç®—ç»“æœã€‚

```c
// ä½ç½®ï¼šggml/src/ggml.c:4217
struct ggml_scratch {
    size_t offs;   // å½“å‰ä½¿ç”¨çš„åç§»
    size_t size;   // æ€»å¤§å°
    void * data;   // æ•°æ®æŒ‡é’ˆ
};

// è®¾ç½® scratch
void ggml_scratch_set(struct ggml_context * ctx, struct ggml_scratch scratch) {
    ctx->scratch = scratch;
}

// ä¿å­˜å½“å‰ scratch çŠ¶æ€
void ggml_scratch_save(struct ggml_context * ctx) {
    ctx->scratch_save = ctx->scratch;
}

// æ¢å¤ scratch çŠ¶æ€ï¼ˆé‡ç”¨å†…å­˜ï¼‰
void ggml_scratch_load(struct ggml_context * ctx) {
    ctx->scratch = ctx->scratch_save;
}
```

### 4.2 ä½¿ç”¨ç¤ºä¾‹

```c
// 1. åˆ†é… scratch ç¼“å†²åŒº
size_t scratch_size = 256*1024*1024;  // 256 MB
void * scratch_buffer = malloc(scratch_size);

struct ggml_scratch scratch = {
    .offs = 0,
    .size = scratch_size,
    .data = scratch_buffer,
};

// 2. è®¾ç½®åˆ° context
ggml_scratch_set(ctx, scratch);

// 3. æ„å»ºè®¡ç®—å›¾ï¼ˆä¼šä½¿ç”¨ scratchï¼‰
struct ggml_tensor * a = ggml_new_tensor_2d(ctx, GGML_TYPE_F32, 1024, 1024);
struct ggml_tensor * b = ggml_new_tensor_2d(ctx, GGML_TYPE_F32, 1024, 1024);
struct ggml_tensor * c = ggml_mul_mat(ctx, a, b);  // ä¸­é—´ç»“æœåœ¨ scratch

// 4. ä¿å­˜çŠ¶æ€
ggml_scratch_save(ctx);

// 5. æ‰§è¡Œè®¡ç®—
ggml_graph_compute(ctx, graph);

// 6. æ¢å¤çŠ¶æ€ï¼ˆé‡ç”¨ scratchï¼‰
ggml_scratch_load(ctx);

// å†æ¬¡ä½¿ç”¨ç›¸åŒçš„ scratch ç©ºé—´
struct ggml_tensor * d = ggml_mul_mat(ctx, c, b);
```

## 5. mmap æ–‡ä»¶æ˜ å°„

### 5.1 mmap åŸç†

mmap å°†æ–‡ä»¶ç›´æ¥æ˜ å°„åˆ°è¿›ç¨‹çš„è™šæ‹Ÿåœ°å€ç©ºé—´ï¼Œé¿å…æ•°æ®æ‹·è´ã€‚

```
ä¼ ç»Ÿæ–‡ä»¶è¯»å–ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   read()   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   memcpy   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç£ç›˜   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ å†…æ ¸   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ ç”¨æˆ·   â”‚
â”‚ æ–‡ä»¶   â”‚           â”‚ ç¼“å†²åŒº â”‚            â”‚ å†…å­˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 2 æ¬¡æ‹·è´

mmap æ˜ å°„ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç£ç›˜   â”‚ â—„â”€â”€â”€â”€â”€â”€â”€> â”‚ ç”¨æˆ·   â”‚
â”‚ æ–‡ä»¶   â”‚   mmap    â”‚ å†…å­˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 0 æ¬¡æ‹·è´ï¼ˆé¡µé¢æ•…éšœæ—¶è‡ªåŠ¨åŠ è½½ï¼‰
```

### 5.2 mmap å®ç°

```cpp
// ä½ç½®ï¼šsrc/llama-mmap.cpp:347
struct llama_mmap {
    void * addr;      // æ˜ å°„åœ°å€
    size_t size;      // æ˜ å°„å¤§å°

#ifdef _WIN32
    HANDLE hFile;
    HANDLE hMapping;
#else
    int fd;
#endif

    // æ„é€ å‡½æ•°ï¼šæ‰“å¼€å¹¶æ˜ å°„æ–‡ä»¶
    llama_mmap(const char * fname, size_t prefetch = 0, bool numa = false) {
#ifdef _WIN32
        // Windows å®ç°
        hFile = CreateFileA(fname, GENERIC_READ, FILE_SHARE_READ,
                           NULL, OPEN_EXISTING, FILE_ATTRIBUTE_NORMAL, NULL);
        if (hFile == INVALID_HANDLE_VALUE) {
            throw std::runtime_error("Cannot open file");
        }

        LARGE_INTEGER file_size;
        GetFileSizeEx(hFile, &file_size);
        size = file_size.QuadPart;

        hMapping = CreateFileMappingA(hFile, NULL, PAGE_READONLY, 0, 0, NULL);
        if (hMapping == NULL) {
            CloseHandle(hFile);
            throw std::runtime_error("CreateFileMapping failed");
        }

        addr = MapViewOfFile(hMapping, FILE_MAP_READ, 0, 0, 0);
        if (addr == NULL) {
            CloseHandle(hMapping);
            CloseHandle(hFile);
            throw std::runtime_error("MapViewOfFile failed");
        }
#else
        // Linux/macOS å®ç°
        fd = open(fname, O_RDONLY);
        if (fd < 0) {
            throw std::runtime_error("Cannot open file");
        }

        struct stat st;
        if (fstat(fd, &st) != 0) {
            close(fd);
            throw std::runtime_error("fstat failed");
        }
        size = st.st_size;

        // å†…å­˜æ˜ å°„
        addr = mmap(NULL, size, PROT_READ, MAP_SHARED, fd, 0);
        if (addr == MAP_FAILED) {
            close(fd);
            throw std::runtime_error("mmap failed");
        }

        // å»ºè®®å†…æ ¸é¢„å–ï¼ˆå¯é€‰ï¼‰
        if (prefetch > 0) {
            size_t prefetch_size = std::min(prefetch, size);
            if (madvise(addr, prefetch_size, MADV_WILLNEED) != 0) {
                // è­¦å‘Šä½†ä¸å¤±è´¥
                fprintf(stderr, "Warning: madvise WILLNEED failed\n");
            }
        }

        // NUMA ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰
        if (numa) {
#ifdef __linux__
            // åˆ†å¸ƒåˆ°æ‰€æœ‰ NUMA èŠ‚ç‚¹
            if (madvise(addr, size, MADV_SEQUENTIAL) == 0) {
                // æç¤ºé¡ºåºè®¿é—®
            }
#endif
        }
#endif
    }

    // ææ„å‡½æ•°ï¼šå–æ¶ˆæ˜ å°„
    ~llama_mmap() {
#ifdef _WIN32
        UnmapViewOfFile(addr);
        CloseHandle(hMapping);
        CloseHandle(hFile);
#else
        munmap(addr, size);
        close(fd);
#endif
    }
};
```

### 5.3 mlockï¼ˆé”å®šå†…å­˜ï¼‰

```cpp
// ä½ç½®ï¼šsrc/llama-mmap.cpp:512
struct llama_mlock {
    void * addr;
    size_t size;

    llama_mlock(void * ptr, size_t len) : addr(ptr), size(len) {
#ifdef _WIN32
        // Windows: VirtualLock
        if (!VirtualLock(addr, size)) {
            fprintf(stderr, "Warning: VirtualLock failed\n");
        }
#else
        // Linux/macOS: mlock
        if (mlock(addr, size) != 0) {
            fprintf(stderr, "Warning: mlock failed: %s\n", strerror(errno));
            // ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œåªæ˜¯è­¦å‘Š
        }
#endif
    }

    ~llama_mlock() {
#ifdef _WIN32
        VirtualUnlock(addr, size);
#else
        munlock(addr, size);
#endif
    }
};
```

**mlock çš„ä½œç”¨**ï¼š
- é˜²æ­¢å†…å­˜é¡µè¢« swap åˆ°ç£ç›˜
- ä¿è¯è®¿é—®å»¶è¿Ÿä¸€è‡´
- é€‚ç”¨äºå¯¹å»¶è¿Ÿæ•æ„Ÿçš„åœºæ™¯

**ä½¿ç”¨å»ºè®®**ï¼š
- åªåœ¨æœ‰è¶³å¤Ÿ RAM æ—¶ä½¿ç”¨
- éœ€è¦ root æƒé™æˆ–é…ç½® ulimit

## 6. Backend Bufferï¼ˆåç«¯ç¼“å†²åŒºï¼‰

### 6.1 Buffer æŠ½è±¡

```c
// ä½ç½®ï¼šggml/include/ggml-backend.h:78
typedef struct ggml_backend_buffer_type * ggml_backend_buffer_type_t;
typedef struct ggml_backend_buffer * ggml_backend_buffer_t;

struct ggml_backend_buffer {
    ggml_backend_buffer_type_t type;  // ç¼“å†²åŒºç±»å‹
    ggml_backend_t backend;           // æ‰€å±åç«¯

    void * context;                   // åç«¯ç‰¹å®šçš„ä¸Šä¸‹æ–‡

    size_t size;                      // ç¼“å†²åŒºå¤§å°
    void * data;                      // æ•°æ®æŒ‡é’ˆï¼ˆCPU å¯è®¿é—®ï¼‰
};

// ç¼“å†²åŒºæ“ä½œæ¥å£
struct ggml_backend_buffer_i {
    void (*free_buffer)(ggml_backend_buffer_t buffer);
    void * (*get_base)(ggml_backend_buffer_t buffer);
    void (*init_tensor)(ggml_backend_buffer_t buffer, struct ggml_tensor * tensor);
    void (*set_tensor)(ggml_backend_buffer_t buffer, struct ggml_tensor * tensor,
                       const void * data, size_t offset, size_t size);
    void (*get_tensor)(ggml_backend_buffer_t buffer, const struct ggml_tensor * tensor,
                       void * data, size_t offset, size_t size);
    bool (*cpy_tensor)(ggml_backend_buffer_t buffer, const struct ggml_tensor * src,
                       struct ggml_tensor * dst);
};
```

### 6.2 CPU Buffer

```c
// ä½ç½®ï¼šggml/src/ggml-backend.cpp:124
static void * ggml_backend_cpu_buffer_get_base(ggml_backend_buffer_t buffer) {
    return buffer->data;
}

static void ggml_backend_cpu_buffer_set_tensor(
    ggml_backend_buffer_t buffer,
    struct ggml_tensor * tensor,
    const void * data,
    size_t offset,
    size_t size) {

    memcpy((char *)tensor->data + offset, data, size);
}

static void ggml_backend_cpu_buffer_get_tensor(
    ggml_backend_buffer_t buffer,
    const struct ggml_tensor * tensor,
    void * data,
    size_t offset,
    size_t size) {

    memcpy(data, (const char *)tensor->data + offset, size);
}

ggml_backend_buffer_t ggml_backend_cpu_buffer_alloc(size_t size) {
    // åˆ†é…å¯¹é½çš„å†…å­˜
    void * data = aligned_alloc(GGML_MEM_ALIGN, size);

    ggml_backend_buffer_t buffer = malloc(sizeof(struct ggml_backend_buffer));
    buffer->type = ggml_backend_cpu_buffer_type();
    buffer->context = NULL;
    buffer->size = size;
    buffer->data = data;

    return buffer;
}
```

### 6.3 GPU Bufferï¼ˆCUDA ç¤ºä¾‹ï¼‰

```cpp
// ä½ç½®ï¼šggml/src/ggml-cuda/ggml-cuda.cpp:2847
static void ggml_backend_cuda_buffer_set_tensor(
    ggml_backend_buffer_t buffer,
    struct ggml_tensor * tensor,
    const void * data,
    size_t offset,
    size_t size) {

    // CPU â†’ GPU ä¼ è¾“
    cudaMemcpy(
        (char *)tensor->data + offset,
        data,
        size,
        cudaMemcpyHostToDevice
    );
}

static void ggml_backend_cuda_buffer_get_tensor(
    ggml_backend_buffer_t buffer,
    const struct ggml_tensor * tensor,
    void * data,
    size_t offset,
    size_t size) {

    // GPU â†’ CPU ä¼ è¾“
    cudaMemcpy(
        data,
        (const char *)tensor->data + offset,
        size,
        cudaMemcpyDeviceToHost
    );
}

ggml_backend_buffer_t ggml_backend_cuda_buffer_alloc(int device, size_t size) {
    cudaSetDevice(device);

    // åˆ†é… GPU å†…å­˜
    void * dev_ptr;
    cudaMalloc(&dev_ptr, size);

    ggml_backend_buffer_t buffer = malloc(sizeof(struct ggml_backend_buffer));
    buffer->type = ggml_backend_cuda_buffer_type(device);
    buffer->context = (void *)(intptr_t)device;
    buffer->size = size;
    buffer->data = dev_ptr;

    return buffer;
}
```

## 7. å†…å­˜ä¼˜åŒ–ç­–ç•¥

### 7.1 è®¡ç®—å†…å­˜éœ€æ±‚

```cpp
size_t estimate_model_memory(const llama_hparams & hparams) {
    size_t mem_size = 0;

    // 1. Token åµŒå…¥å±‚: [n_vocab, n_embd]
    mem_size += hparams.n_vocab * hparams.n_embd * sizeof(float);

    // 2. æ¯ä¸ª Transformer å±‚
    for (int i = 0; i < hparams.n_layer; i++) {
        // Q, K, V æŠ•å½±: [n_embd, n_embd] * 3
        mem_size += 3 * hparams.n_embd * hparams.n_embd * sizeof(float);

        // è¾“å‡ºæŠ•å½±: [n_embd, n_embd]
        mem_size += hparams.n_embd * hparams.n_embd * sizeof(float);

        // FFN: [n_embd, n_ff] * 3 (gate, up, down)
        mem_size += 3 * hparams.n_embd * hparams.n_ff * sizeof(float);

        // Layer Norm æƒé‡: [n_embd] * 2
        mem_size += 2 * hparams.n_embd * sizeof(float);
    }

    // 3. è¾“å‡ºå±‚: [n_embd, n_vocab]
    mem_size += hparams.n_embd * hparams.n_vocab * sizeof(float);

    // 4. é¢å¤–å¼€é”€ï¼ˆå…ƒæ•°æ®ã€å¯¹é½ç­‰ï¼‰
    mem_size = (size_t)(mem_size * 1.1);

    return mem_size;
}
```

### 7.2 åŠ¨æ€å†…å­˜ç®¡ç†

```cpp
// æ ¹æ®å¯ç”¨å†…å­˜åŠ¨æ€è°ƒæ•´
size_t available_mem = get_available_system_memory();
size_t model_mem = estimate_model_memory(hparams);

if (available_mem < model_mem) {
    // å†…å­˜ä¸è¶³ï¼Œä½¿ç”¨æ›´æ¿€è¿›çš„ç­–ç•¥

    // ç­–ç•¥ 1: å‡å°‘ KV ç¼“å­˜å¤§å°
    ctx_params.n_ctx = 1024;  // è€Œä¸æ˜¯ 4096

    // ç­–ç•¥ 2: éƒ¨åˆ† offload åˆ° GPU
    model_params.n_gpu_layers = 16;  // è€Œä¸æ˜¯å…¨éƒ¨

    // ç­–ç•¥ 3: ä½¿ç”¨æ›´å¤šçš„ CPUï¼Œå‡å°‘æ‰¹å¤§å°
    ctx_params.n_batch = 128;  // è€Œä¸æ˜¯ 512

    fprintf(stderr, "Warning: Limited memory, using conservative settings\n");
}
```

### 7.3 å†…å­˜æ± å¤ç”¨

```cpp
// å¤šä¸ª context å…±äº«ä¸€ä¸ªå†…å­˜æ± 
void * shared_buffer = malloc(512*1024*1024);  // 512 MB

struct ggml_init_params params1 = {
    .mem_size   = 256*1024*1024,
    .mem_buffer = shared_buffer,
    .no_alloc   = false,
};
struct ggml_context * ctx1 = ggml_init(params1);

// ä½¿ç”¨ ctx1...

ggml_free(ctx1);

// å¤ç”¨ç›¸åŒçš„ buffer
struct ggml_init_params params2 = {
    .mem_size   = 256*1024*1024,
    .mem_buffer = shared_buffer,
    .no_alloc   = false,
};
struct ggml_context * ctx2 = ggml_init(params2);
```

## 8. å®è·µç»ƒä¹ 

### ç»ƒä¹  1ï¼šå†…å­˜ä½¿ç”¨åˆ†æ

ç¼–å†™å·¥å…·åˆ†ææ¨¡å‹çš„å†…å­˜ä½¿ç”¨ï¼š

```cpp
void analyze_memory_usage(struct ggml_context * ctx) {
    size_t total_size = 0;
    int n_tensors = 0;

    std::map<ggml_type, size_t> size_by_type;

    for (struct ggml_object * obj = ctx->objects_begin;
         obj != NULL; obj = obj->next) {

        if (obj->type == GGML_OBJECT_TYPE_TENSOR) {
            struct ggml_tensor * tensor = (struct ggml_tensor *)
                ((char *)ctx->mem_buffer + obj->offs);

            size_t tensor_size = ggml_nbytes(tensor);
            total_size += tensor_size;
            n_tensors++;

            size_by_type[tensor->type] += tensor_size;
        }
    }

    printf("Memory Analysis:\n");
    printf("  Total tensors: %d\n", n_tensors);
    printf("  Total size: %.2f MB\n", total_size / (1024.0 * 1024));

    for (auto & [type, size] : size_by_type) {
        printf("  %s: %.2f MB (%.1f%%)\n",
               ggml_type_name(type),
               size / (1024.0 * 1024),
               100.0 * size / total_size);
    }
}
```

### ç»ƒä¹  2ï¼šè‡ªå®šä¹‰å†…å­˜åˆ†é…å™¨

å®ç°ä¸€ä¸ªç®€å•çš„ arena åˆ†é…å™¨ï¼š

```cpp
class ArenaAllocator {
    char * buffer;
    size_t size;
    size_t offset;

public:
    ArenaAllocator(size_t sz) : size(sz), offset(0) {
        buffer = (char *)malloc(sz);
    }

    ~ArenaAllocator() {
        free(buffer);
    }

    void * allocate(size_t sz, size_t align = 16) {
        // å¯¹é½
        offset = (offset + align - 1) & ~(align - 1);

        if (offset + sz > size) {
            throw std::bad_alloc();
        }

        void * ptr = buffer + offset;
        offset += sz;
        return ptr;
    }

    void reset() {
        offset = 0;  // é‡ç”¨æ‰€æœ‰å†…å­˜
    }

    size_t used() const { return offset; }
    size_t available() const { return size - offset; }
};
```

## 9. æ€»ç»“

ä»Šå¤©æˆ‘ä»¬æ·±å…¥å­¦ä¹ äº† GGML çš„å†…å­˜ç®¡ç†ï¼š

âœ… **Context æœºåˆ¶**ï¼šå†…å­˜æ± ç®¡ç†ä¸å¯¹è±¡åˆ†é…
âœ… **Scratch å†…å­˜**ï¼šä¸´æ—¶å†…å­˜çš„é«˜æ•ˆå¤ç”¨
âœ… **mmap æŠ€æœ¯**ï¼šé›¶æ‹·è´æ–‡ä»¶æ˜ å°„
âœ… **Backend Buffer**ï¼šç»Ÿä¸€çš„åç«¯ç¼“å†²åŒºæ¥å£
âœ… **ä¼˜åŒ–ç­–ç•¥**ï¼šåŠ¨æ€è°ƒæ•´ä¸å†…å­˜å¤ç”¨

### å…³é”®è¦ç‚¹

1. **å†…å­˜æ± **ï¼šå‡å°‘é¢‘ç¹åˆ†é…ï¼Œæé«˜æ€§èƒ½
2. **mmap**ï¼šå¤§æ–‡ä»¶å¿«é€ŸåŠ è½½ï¼ŒèŠ‚çœå†…å­˜
3. **å¯¹é½**ï¼šä¿è¯ SIMD å’Œ GPU æ€§èƒ½
4. **å¤ç”¨**ï¼šScratch æœºåˆ¶é¿å…é‡å¤åˆ†é…

## ä¸‹ä¸€æ­¥

æ˜å¤©æˆ‘ä»¬å°†å­¦ä¹  **Day 7: è®¡ç®—å›¾æ„å»ºä¸è°ƒåº¦**ï¼š
- llama_graph_builder å®ç°
- æ„å»ºå®Œæ•´çš„ Transformer è®¡ç®—å›¾
- åç«¯è°ƒåº¦å™¨åŸç†
- å›¾ä¼˜åŒ–æŠ€æœ¯

---

**ç»ƒä¹ **ï¼š
1. åˆ†æä¸€ä¸ªæ¨¡å‹çš„å†…å­˜ä½¿ç”¨åˆ†å¸ƒ
2. å¯¹æ¯” mmap å’Œä¼ ç»ŸåŠ è½½çš„æ€§èƒ½å·®å¼‚
3. å®ç°ä¸€ä¸ªç®€å•çš„å†…å­˜æ± ç®¡ç†å™¨

ğŸ“š [Day 7: è®¡ç®—å›¾æ„å»ºä¸è°ƒåº¦](day07-computation-graph.md)
